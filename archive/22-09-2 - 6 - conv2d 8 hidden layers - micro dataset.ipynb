{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffa863f-8872-4bf0-b498-2aaad36ba0a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN built from scratch to solve SETI Breakthrough Listen Kaggle challenge\n",
    "\n",
    "This notebook aims to use a handcrafted CNN deep learning model to solve the SETI Breakthrough Listen Kaggle challenge:\n",
    "-  https://www.kaggle.com/competitions/seti-breakthrough-listen"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Python packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15797265-4be7-4f48-8cbd-861d1b7b9696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:30.748587Z",
     "iopub.status.busy": "2022-09-02T17:05:30.747791Z",
     "iopub.status.idle": "2022-09-02T17:05:41.371813Z",
     "shell.execute_reply": "2022-09-02T17:05:41.371140Z",
     "shell.execute_reply.started": "2022-09-02T17:05:30.748524Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: albumentations in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (1.9.0)\n",
      "Requirement already satisfied: qudida>=0.0.4 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (1.23.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: PyYAML in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.20.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2022.7.28)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchsummary in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (1.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Used for transforming images\n",
    "!pip install albumentations\n",
    "\n",
    "# Installs CUDA version of PyTorch, allowing to run on a GPU\n",
    "# !pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "# Used for displaying model summaries\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Python packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b60974-9c19-42ce-bd33-8f6a6539de7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:41.373237Z",
     "iopub.status.busy": "2022-09-02T17:05:41.373046Z",
     "iopub.status.idle": "2022-09-02T17:05:43.544176Z",
     "shell.execute_reply": "2022-09-02T17:05:43.543642Z",
     "shell.execute_reply.started": "2022-09-02T17:05:41.373219Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility packages\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# PyTorch packages for training a model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# Utility package used to visualise CNN filters\n",
    "from torchvision import utils\n",
    "\n",
    "# Scikit learn packages\n",
    "from sklearn.decomposition import NMF # Used to factorise an image into two matrices\n",
    "from sklearn.metrics import roc_auc_score, classification_report # metric reporting\n",
    "\n",
    "# OpenCV package used to transform images\n",
    "import cv2\n",
    "\n",
    "# Packages to help with data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Used to plot graphs\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Used to transform images\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global Configuration\n",
    "\n",
    "A global configuration object, allowing important variables to be easily changed and referenced."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fee657-5f4b-497a-8fe3-df9314d21334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:43.545194Z",
     "iopub.status.busy": "2022-09-02T17:05:43.544900Z",
     "iopub.status.idle": "2022-09-02T17:05:43.548601Z",
     "shell.execute_reply": "2022-09-02T17:05:43.548125Z",
     "shell.execute_reply.started": "2022-09-02T17:05:43.545177Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_workers': 4,\n",
    "    'model': 'eca_nfnet_l0',\n",
    "    'device': 'cuda',\n",
    "    'image_size': 224,\n",
    "    'input_channels': 1,\n",
    "    'output_features': 1,\n",
    "    'seed': 42,\n",
    "    'target_size': 1,\n",
    "    'T_max': 10,\n",
    "    'min_lr': 1e-6,\n",
    "    'lr': 1e-6,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 50,\n",
    "    'epochs': 1,\n",
    "    'num_folds': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Seed Initalisation\n",
    "\n",
    "Sets the seeds for random functions to fixed values.\n",
    "\n",
    "This allows the results in this notebook to be reproducible."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "set_seeds(seed=config['seed'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4e7ab849-07f8-4129-86e5-cd32aeb0da38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "The dataset labels are loaded from file.\n",
    "\n",
    "These are then stored in a Pandas DataFrame for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f714664-3223-4271-a71b-be2d4b5e1ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:43.554828Z",
     "iopub.status.busy": "2022-09-02T17:05:43.554676Z",
     "iopub.status.idle": "2022-09-02T17:05:58.574584Z",
     "shell.execute_reply": "2022-09-02T17:05:58.573993Z",
     "shell.execute_reply.started": "2022-09-02T17:05:43.554815Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/dataset_500\\\\500_balanced_labels.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m labels_filepath \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(train_data_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m500_balanced_labels.npy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# open as a Numpy pickle file\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlabels_filepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      7\u001B[0m     initial_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(f, allow_pickle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# load into a Pandas dataframe\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/datasets/dataset_500\\\\500_balanced_labels.npy'"
     ]
    }
   ],
   "source": [
    "# build the path to the labels file\n",
    "train_data_dir = r'/datasets/dataset_500'\n",
    "labels_filepath = os.path.join(train_data_dir, '500_balanced_labels.npy')\n",
    "\n",
    "# open as a Numpy pickle file\n",
    "with open(labels_filepath, 'rb') as f:\n",
    "    initial_data = np.load(f, allow_pickle=True)\n",
    "\n",
    "# load into a Pandas dataframe\n",
    "initial_data_df = pd.DataFrame(initial_data, columns=['id', 'target', 'image_filepath']).convert_dtypes()\n",
    "initial_data_df['target'] = initial_data_df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc517db8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Shuffle data\n",
    "\n",
    "The entire dataset is shuffled.\n",
    "\n",
    "This ensures that there is an equal distribution of classes in the training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84af663",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.575712Z",
     "iopub.status.busy": "2022-09-02T17:05:58.575529Z",
     "iopub.status.idle": "2022-09-02T17:05:58.579636Z",
     "shell.execute_reply": "2022-09-02T17:05:58.579180Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.575697Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initial_data_df = initial_data_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the training dataset consists of the following fields:\n",
    "\n",
    "- `id`: The ID of the data sample.\n",
    "- `target`: The ground truth label sample.\n",
    "- `image_filepath`: The location of the image file on disk."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8ad26-0de7-42c2-8684-c1958d015745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.580525Z",
     "iopub.status.busy": "2022-09-02T17:05:58.580372Z",
     "iopub.status.idle": "2022-09-02T17:05:58.588217Z",
     "shell.execute_reply": "2022-09-02T17:05:58.587773Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.580511Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initial_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30f8d7-098a-4035-a6a4-ce4cad9df526",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split the data into 70% train and 30% test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7aee7e-c61c-4864-b44c-ead695da5486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.589226Z",
     "iopub.status.busy": "2022-09-02T17:05:58.588760Z",
     "iopub.status.idle": "2022-09-02T17:05:58.592631Z",
     "shell.execute_reply": "2022-09-02T17:05:58.592183Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.589212Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_split_mask = np.random.rand(len(initial_data_df)) < 0.7\n",
    "\n",
    "train_df = initial_data_df[data_split_mask]\n",
    "test_df = initial_data_df[~data_split_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e10f3-524f-4606-a7d4-1d2604adf3c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Image Utility Functions\n",
    "\n",
    "Define a set of utility functions for manipulating images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8574b7",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.593300Z",
     "iopub.status.busy": "2022-09-02T17:05:58.593154Z",
     "iopub.status.idle": "2022-09-02T17:05:58.598868Z",
     "shell.execute_reply": "2022-09-02T17:05:58.598429Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.593288Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Resizes an image to the specified size.\n",
    "'''\n",
    "def resize_image(image):\n",
    "    return cv2.resize(image, dsize=(config['image_size'], config['image_size']), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Plots an image.\n",
    "'''\n",
    "def plot_image(image):\n",
    "    plt.figure(figsize = (20, 6))\n",
    "    plt.imshow(image, aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Min-max normalises the image pixel values (between 0 and 1).\n",
    "'''\n",
    "def normalise_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "\n",
    "    return (image - image_min) / (image_max - image_min)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Factorises an image into two matrices, and returns them.\n",
    "Used to help remove image background noise.\n",
    "'''\n",
    "def get_decomposition_matrices(image):\n",
    "    model = NMF(n_components=2, init='random', random_state=0)\n",
    "    W = model.fit_transform(image + 100) # add 100 to ensure no negative values\n",
    "    H = model.components_\n",
    "\n",
    "    return (W, H)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Removes the background noise from a set of sample images.\n",
    "\n",
    "Based on: https://www.kaggle.com/competitions/seti-breakthrough-listen/discussion/245950\n",
    "'''\n",
    "def get_denoised_image(sample_images):\n",
    "    combined_on_images = None\n",
    "    combined_off_images = None\n",
    "    combined_denoised_image = None\n",
    "\n",
    "    for i in range(0, len(sample_images), 2):\n",
    "        on_target_image = sample_images[i] # Get on target image\n",
    "        off_target_image = sample_images[i+1] # Get off target image\n",
    "\n",
    "        on_W, on_H = get_decomposition_matrices(on_target_image) # Decompose on target images into factor matrices\n",
    "        off_W, off_H = get_decomposition_matrices(off_target_image) # Decomponse off target images into factor matrices\n",
    "\n",
    "        # Get noise approximation by multiplying a factor matrix from each of the on target, and off target images.\n",
    "        # Then subtract the approximated noise from the on target images\n",
    "        denoised_image = normalise_image(on_target_image - np.matmul(on_W, off_H))\n",
    "\n",
    "        # Consolidate the on target, off target and denoised images.\n",
    "        combined_on_images = on_target_image if combined_on_images is None else combined_on_images + on_target_image\n",
    "        combined_off_images = off_target_image if combined_off_images is None else combined_off_images + off_target_image\n",
    "        combined_denoised_image = denoised_image if combined_denoised_image is None else combined_denoised_image + denoised_image\n",
    "\n",
    "    # Return the denoised image\n",
    "    return combined_denoised_image"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Dataset\n",
    "\n",
    "An implementation of the PyTorch `Dataset` class.\n",
    "\n",
    "Used by the model to access a data sample."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f521d-c146-492a-afad-4b13fbf2ce8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.601047Z",
     "iopub.status.busy": "2022-09-02T17:05:58.600723Z",
     "iopub.status.idle": "2022-09-02T17:05:58.605262Z",
     "shell.execute_reply": "2022-09-02T17:05:58.604839Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.601033Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, targets, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images_filepath = self.images_filepaths[idx]\n",
    "        images_filepath = images_filepath.replace('\\\\', '/')\n",
    "        file_name = os.path.basename(images_filepath)\n",
    "        images_filepath = f'/datasets/dataset_500/{file_name}'\n",
    "\n",
    "        # the sample image is loaded from a Numpy pickle file on disk\n",
    "        images = np.load(images_filepath).astype(np.float32)\n",
    "\n",
    "        # after the image is loaded into memory, it is denoised\n",
    "        image = get_denoised_image(images)\n",
    "\n",
    "        # apply image transformations if requested\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "        else:\n",
    "            image = resize_image(image)\n",
    "            image = image[np.newaxis,:,:]\n",
    "            image = torch.from_numpy(image).float()\n",
    "\n",
    "        label = torch.tensor(self.targets[idx]).float()\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f62240-81da-4110-b0b6-103ab07cf1e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Image Augmentation\n",
    "\n",
    "Helper functions for transforming images.\n",
    "\n",
    "These can be used to help prevent overfitting on the available data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cd0bf-9ce7-4159-b2ad-a757c8fe228a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.607651Z",
     "iopub.status.busy": "2022-09-02T17:05:58.607300Z",
     "iopub.status.idle": "2022-09-02T17:05:58.611609Z",
     "shell.execute_reply": "2022-09-02T17:05:58.611179Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.607637Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns a set of image transformations using the albumentations library.\n",
    "'''\n",
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(config['image_size'], config['image_size']),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=180, p=0.7),\n",
    "            albumentations.RandomBrightnessContrast(brightness_limit=0.6, p=0.5),\n",
    "            albumentations.CoarseDropout(max_holes=10, max_height=12, max_width=12, fill_value=0),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.25, scale_limit=0.1, rotate_limit=0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Applies transformations for validation image data.\n",
    "\n",
    "This currently resizes the images.\n",
    "'''\n",
    "def get_valid_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(config['image_size'],config['image_size']),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Applies transformations for training image data.\n",
    "\n",
    "This currently resizes the images.\n",
    "'''\n",
    "def get_test_transforms():\n",
    "        return albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Resize(config['image_size'], config['image_size']),\n",
    "                ToTensorV2(p=1.0)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c665f4-ba86-4749-b576-dabcbbe81928",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mixup\n",
    "\n",
    "Mixup is an image augmentation technique that can also help prevent overfitting on the training data.\n",
    "\n",
    "This works by overlaying two images by applying a transparency effect to the one on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f3584-8f00-401b-9910-614f159e5f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.612261Z",
     "iopub.status.busy": "2022-09-02T17:05:58.612117Z",
     "iopub.status.idle": "2022-09-02T17:05:58.616389Z",
     "shell.execute_reply": "2022-09-02T17:05:58.615972Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.612249Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Given two images, x and y, use the alpha value to overlay them.\n",
    "'''\n",
    "def mixup(x, y, alpha=1.0, use_cuda=True):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :] # the composite image\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Criterion to decide how much mixup to apply based on the sample prediction.\n",
    "\n",
    "This allows the model to have a higher representation of samples that\n",
    "it has a higher classification error on.\n",
    "'''\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50022801-d8c5-4b8e-8c17-a247403a4154",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Weight Random Sampler\n",
    "\n",
    "Returns a weighted sample from the training dataset.\n",
    "\n",
    "The weighting helps ensure an equal amount of negative and positive samples are returned when there is an unequal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0ca22-8222-46a8-b252-3db2932bf2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.617023Z",
     "iopub.status.busy": "2022-09-02T17:05:58.616874Z",
     "iopub.status.idle": "2022-09-02T17:05:58.620449Z",
     "shell.execute_reply": "2022-09-02T17:05:58.620035Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.617011Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Return a sample from the training data.\n",
    "\n",
    "The sample selection is weighted so that there is an equal chance\n",
    "for a sample from each class being selected.\n",
    "'''\n",
    "def get_sampler(train_data):\n",
    "    class_counts = train_data['target'].value_counts().to_list()\n",
    "    num_samples = sum(class_counts)\n",
    "    labels = train_data['target'].to_list()\n",
    "\n",
    "    class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "    weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "    return WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056abd0c-c12a-4a0a-8e73-c7b64aa6432e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train and Validation Dataloaders\n",
    "\n",
    "Data loaders for the training and validation data.\n",
    "\n",
    "These are used during the model training and validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0ba19-0137-4913-bdb2-897ee0a6c52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.621258Z",
     "iopub.status.busy": "2022-09-02T17:05:58.620971Z",
     "iopub.status.idle": "2022-09-02T17:05:58.624772Z",
     "shell.execute_reply": "2022-09-02T17:05:58.624375Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.621245Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_loaders(train_data, valid_data, sampler):\n",
    "    training_set = CustomDataset(\n",
    "        images_filepaths=train_data['image_filepath'].values,\n",
    "        targets=train_data['target'].values,\n",
    "        # transform=get_train_transforms()\n",
    "    )\n",
    "\n",
    "    validation_set = CustomDataset(\n",
    "        images_filepaths=valid_data['image_filepath'].values,\n",
    "        targets=valid_data['target'].values,\n",
    "        # transform=get_valid_transforms()\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        training_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        # shuffle=True,\n",
    "        # num_workers=config['num_workers'],\n",
    "        sampler = sampler,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        validation_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        # num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a10f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "The deep learning model that will be trained.\n",
    "\n",
    "Based on the example from:\n",
    "- https://machinelearningknowledge.ai/pytorch-conv2d-explained-with-examples/#Example_of_PyTorch_Conv2D_in_CNN\n",
    "\n",
    "The layers consist of the following:\n",
    "- Layers 1 - 8:\n",
    "-- 2D convolutional layer\n",
    "-- Batch normalisation layer\n",
    "-- ReLU activation layer\n",
    "-- 2D max pooling layer\n",
    "\n",
    "The final layer is a fully connected layer that connects all of the neurons in the previous layer and outputs a binary classification using a confidence score.\n",
    "\n",
    "The weights for the final layer are randomly initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6edd8d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.625405Z",
     "iopub.status.busy": "2022-09-02T17:05:58.625261Z",
     "iopub.status.idle": "2022-09-02T17:05:58.633911Z",
     "shell.execute_reply": "2022-09-02T17:05:58.633472Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.625393Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create a deep convolutional neural network with a binary classification output.\n",
    "'''\n",
    "class CustomModel(nn.Module):\n",
    "    '''\n",
    "    This function is called when setting up the model.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(1204),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 2048, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # convolutional layer\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(2048, 4096, kernel_size=3, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(4098),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # classification layer\n",
    "        self.fc1 = nn.Linear(256, 1, bias=True)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "\n",
    "    '''\n",
    "    This method is called when making a prediction\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size(0), -1) # flatten for FC\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45228b74-1e35-4363-b7f8-ce49d8945286",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Initialisation\n",
    "\n",
    "Initialise model, loss criterion, optimiser and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94530cde-2cb0-420d-954f-251bf7115d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T17:05:58.634651Z",
     "iopub.status.busy": "2022-09-02T17:05:58.634478Z",
     "iopub.status.idle": "2022-09-02T17:06:00.683583Z",
     "shell.execute_reply": "2022-09-02T17:06:00.683043Z",
     "shell.execute_reply.started": "2022-09-02T17:05:58.634617Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the model to train\n",
    "model = CustomModel()\n",
    "model = model.to(config['device'])\n",
    "\n",
    "# the loss function used to track loss\n",
    "# this allows loss to be tracked with an aim of reducing it during training\n",
    "criterion = nn.BCEWithLogitsLoss().to(config['device'])\n",
    "\n",
    "# Optimizer used for minimising loss during model training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "# learning rate scheduler\n",
    "# starts the learning rate at a high value and reduces by steps over time\n",
    "scheduler = CosineAnnealingLR(optimizer,\n",
    "                              T_max=config['T_max'],\n",
    "                              eta_min=config['min_lr'],\n",
    "                              last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f277d9a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification Utility Functions\n",
    "\n",
    "A set of functions that help get a binary predictions and to measure their accuracy and ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769bbe46",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-02T17:06:00.684584Z",
     "iopub.status.busy": "2022-09-02T17:06:00.684382Z",
     "iopub.status.idle": "2022-09-02T17:06:00.691702Z",
     "shell.execute_reply": "2022-09-02T17:06:00.691173Z",
     "shell.execute_reply.started": "2022-09-02T17:06:00.684567Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Min max normalises prediction values.\n",
    "This places them in the range 0 - 1.\n",
    "'''\n",
    "def get_normalised_predictions(predictions):\n",
    "    predictions_min = min(predictions)\n",
    "    predictions_max = max(predictions)\n",
    "\n",
    "    if predictions_min == predictions_max: # all predictions are the same\n",
    "        return [0] * len(predictions)\n",
    "\n",
    "    return [(x - predictions_min) / (predictions_max - predictions_min) for x in predictions]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Classifies as false for values below 0.5 and true otherwise.\n",
    "'''\n",
    "def get_binary_classification(value):\n",
    "    return 0 if value < 0.5 else 1\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Returns the binary classifications for a set of raw model predictions.\n",
    "'''\n",
    "def get_binary_classifications(predictions):\n",
    "    norm_predictions = np.array(get_normalised_predictions(predictions))\n",
    "    binary_classification_func = np.vectorize(get_binary_classification)\n",
    "\n",
    "    return binary_classification_func(norm_predictions)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Returns the accuracy score for a set of predictions.\n",
    "'''\n",
    "def get_accuracy(predictions, labels):\n",
    "    binary_classifications = get_binary_classifications(predictions)\n",
    "    labels_array = labels.cpu().detach().numpy()\n",
    "    correct_predictions = (binary_classifications == labels_array)\n",
    "    correct_predictions_count = np.count_nonzero(correct_predictions)\n",
    "\n",
    "    return np.mean(correct_predictions_count / len(predictions))\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Returns the ROC AUC score for a prediction.\n",
    "'''\n",
    "def get_roc_auc_score(output, target):\n",
    "    try:\n",
    "        return round(roc_auc_score(target, output), 10)\n",
    "    except:\n",
    "        return 0.5 # return 0.5 score if an exception occours, e.g. divide by 0\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Evaluates a model by predicting values for a supplied dataset.\n",
    "\n",
    "Returns loss, accuracy and ROC AUC metrics for the predictions.\n",
    "'''\n",
    "def get_validation_loss_accuracy_rocauc(model, data_loader):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    roc_auc = 0\n",
    "\n",
    "    # place model in evaluation mode so weights are not updated\n",
    "    model.eval()\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        x, y = x.to(config['device']), y.to(config['device'])\n",
    "\n",
    "        predictions = model(x)\n",
    "\n",
    "        loss += criterion(predictions, y.unsqueeze(1)).item()\n",
    "        accuracy += get_accuracy(predictions.cpu().detach().numpy(), y.unsqueeze(1))\n",
    "        roc_auc += get_roc_auc_score(predictions, y.unsqueeze(1))\n",
    "\n",
    "\n",
    "    num_samples = len(data_loader)\n",
    "\n",
    "    return loss/num_samples, accuracy/num_samples, roc_auc/num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Validation Loop\n",
    "\n",
    "The main loop for training and validating the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b265ec8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-02T17:06:00.692572Z",
     "iopub.status.busy": "2022-09-02T17:06:00.692399Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data into training and validation set with an 80:20 ratio\n",
    "train_data = train_df.iloc[:400,:]\n",
    "valid_data = train_df.iloc[400:,:]\n",
    "\n",
    "# data sample loaders\n",
    "train_loader, valid_loader = get_loaders(train_df, valid_data, None)\n",
    "\n",
    "# global variables used to keep track of metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_roc_auc_scores = []\n",
    "\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "valid_roc_auc_scores = []\n",
    "\n",
    "\n",
    "\n",
    "# the training & validation loop, that runs for the number of epochs specified\n",
    "for e in range(1, config['epochs']+1):\n",
    "    # variables to track metrics for the epoch\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    epoch_train_roc_auc = 0\n",
    "\n",
    "    epoch_valid_loss = 0\n",
    "    epoch_valid_acc = 0\n",
    "    epoch_valid_roc_auc = 0\n",
    "\n",
    "    start_time = time.time() # use a timer to track of how long an epoch takes\n",
    "\n",
    "    # train the model using the training data set\n",
    "    for train_x, train_y in train_loader:\n",
    "        # train_x is the batched image samples\n",
    "        # train_y is the batched labels\n",
    "        train_x, train_y = train_x.to(config['device']), train_y.to(config['device'])\n",
    "\n",
    "        # reset the optimizer by zeroing out its gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # --------\n",
    "        # Training\n",
    "        # --------\n",
    "        model.train() # put model into training mode so weights can be updated\n",
    "\n",
    "        train_predictions = model(train_x) # get predictions from training set\n",
    "\n",
    "        # calculate training loss\n",
    "        train_loss = criterion(train_predictions, train_y.unsqueeze(1))\n",
    "        epoch_train_loss += train_loss.item()\n",
    "\n",
    "        # calculate training accuracy\n",
    "        train_acc = get_accuracy(train_predictions.cpu().detach().numpy(), train_y.unsqueeze(1))\n",
    "        epoch_train_acc += train_acc.item()\n",
    "\n",
    "        # calculate training ROC AUC score\n",
    "        epoch_train_roc_auc += get_roc_auc_score(train_predictions, train_y)\n",
    "\n",
    "\n",
    "        # ----------\n",
    "        # Validation\n",
    "        # ----------\n",
    "        # run model against validation data and get metrics\n",
    "        valid_loss, valid_acc, valid_roc_auc = get_validation_loss_accuracy_rocauc(model, valid_loader)\n",
    "\n",
    "        epoch_valid_loss += valid_loss\n",
    "        epoch_valid_acc += valid_acc\n",
    "        epoch_valid_roc_auc += valid_roc_auc\n",
    "\n",
    "\n",
    "        # -------------------\n",
    "        # Back propagation\n",
    "        # -------------------\n",
    "        train_loss.backward() # update the model weights using back propagation\n",
    "        optimizer.step() # update the optimizer for reducing loss\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    num_samples = len(train_loader)\n",
    "\n",
    "    # store the training and validation metrics for the epoch\n",
    "    train_losses.append(epoch_train_loss / num_samples)\n",
    "    train_accuracies.append(epoch_train_acc / num_samples)\n",
    "    train_roc_auc_scores.append(epoch_train_roc_auc / num_samples)\n",
    "\n",
    "    valid_losses.append(epoch_valid_loss / num_samples)\n",
    "    valid_accuracies.append(epoch_valid_acc / num_samples)\n",
    "    valid_roc_auc_scores.append(epoch_valid_roc_auc / num_samples)\n",
    "\n",
    "    # print the metrics for tracking purposes\n",
    "    print(f'Epoch {e+0:03}:'\n",
    "          f' | Train - Loss: {epoch_train_loss / num_samples:.5f}'\n",
    "          f' | Acc: {epoch_train_acc / num_samples:.3f}'\n",
    "          f' | ROC AUC: {epoch_valid_roc_auc / num_samples:.3f}'\n",
    "          f' | Duration (s): {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d995cba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save Model\n",
    "\n",
    "Save the model state to disk for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a573d7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'cnn_from_scratch.pth'\n",
    "current_datetime = datetime.now().strftime(\"%y-%m-%d_%H-%M-%S\")\n",
    "models_dir = os.path.join('models', current_datetime)\n",
    "\n",
    "os.mkdir(models_dir)\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(models_dir, model_name))\n",
    "\n",
    "print('model saved to: ', os.path.join(models_dir, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Metrics\n",
    "\n",
    "Plot the metrics gathered during training and validation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcebaeb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training loss\n",
    "plt.title('Training loss per batch')\n",
    "plt.plot(train_losses[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc29f04",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# validation loss\n",
    "plt.title('Validation loss per batch')\n",
    "plt.plot(valid_losses[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37a98f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train roc auc\n",
    "plt.title('Train ROC AUC per batch')\n",
    "plt.plot(train_roc_auc_scores[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf9207",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training accuracy\n",
    "plt.title('Training accuracy per batch')\n",
    "plt.plot(train_accuracies[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03b6f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# validation accuracy\n",
    "plt.title('Validation accuracy per batch')\n",
    "plt.plot(valid_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6efbb9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# validation roc auc\n",
    "plt.title('Validation ROC AUC per batch')\n",
    "plt.plot(valid_roc_auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524c160",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluate the model against the test data set.\n",
    "\n",
    "This is representative of how the model will perform in real life as it has not seen the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf291371",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data loader for the test data.\n",
    "'''\n",
    "def get_test_loader(test_data):\n",
    "    test_set = CustomDataset(\n",
    "        images_filepaths=test_data['image_filepath'].values,\n",
    "        targets=test_data['target'].values,\n",
    "        # transform=get_valid_transforms()\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        test_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        # num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the model predictions for the test data set:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ec53b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_targets = []\n",
    "test_outputs = []\n",
    "\n",
    "model.cuda() # run the model on GPU\n",
    "model.eval() # put model in evaluation mode so weights are not affected\n",
    "\n",
    "# run the model against the test data and gather the predictions\n",
    "for X_batch, y_batch in get_test_loader(test_df):\n",
    "    X_batch, y_batch = X_batch.to(config['device']), y_batch.to(config['device'])\n",
    "\n",
    "    y_pred = model(X_batch)\n",
    "\n",
    "    test_targets.append(y_batch)\n",
    "    test_outputs.extend([t.item() for t in y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786f279",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The prediction values are in a range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f475a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562bdd4b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To help convert to a binary classification, normalise between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7f94d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalised_predictions = get_normalised_predictions(test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf74b8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(normalised_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a1d61",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use 0.5 as a threshold to map the predictions into binary classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cd202",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_targets_float = [x.cpu().numpy() for x in test_targets]\n",
    "test_targets_float = np.concatenate(test_targets_float, axis=0).tolist()\n",
    "test_outputs_binary = [0 if x < 0.5 else 1.0 for x in normalised_predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create and display the test results dataframe for verification:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ed0a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame([test_targets_float, test_outputs_binary])\n",
    "\n",
    "test_results_df = test_results_df.transpose()\n",
    "test_results_df.columns = ['label', 'prediction']\n",
    "\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display a confusion matrix to give an overview of how the model classified the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f930eede",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(test_results_df['prediction'], test_results_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print classification metrics:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a9b5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_results_df['prediction'], test_results_df['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf8806",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualise Filters\n",
    "\n",
    "To help understand how the model works, the convolutional filters for the first layer are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb2990",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = CustomModel()\n",
    "# model.load_state_dict(torch.load(os.path.join(models_dir, model_name)))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11bae7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plots the filter for a convolutional kernel.\n",
    "'''\n",
    "def plot_filter(kernel):\n",
    "    # normalise between 0 and 1\n",
    "    normalised_kernel = kernel - kernel.min()\n",
    "    normalised_kernel = normalised_kernel / normalised_kernel.max()\n",
    "\n",
    "    # make a grid of images\n",
    "    filter = utils.make_grid(normalised_kernel, nrow = 12)\n",
    "\n",
    "    # matplotlib uses (height x width x channels) format\n",
    "    # pytorch uses (batch index x channel x height x width) format\n",
    "    plt.imshow(filter.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd90ea8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the kernel for the first layer\n",
    "kernel = model.layer1[0].weight.detach().clone()\n",
    "\n",
    "# print its size and plot its filters\n",
    "print(kernel.size())\n",
    "plot_filter(kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}