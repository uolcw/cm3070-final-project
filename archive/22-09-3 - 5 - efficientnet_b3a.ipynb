{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffa863f-8872-4bf0-b498-2aaad36ba0a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SETI Breakthrough Listen challenge solution based on pretrained EfficientNet model\n",
    "\n",
    "An attempt to classify the SETI signals based on the Kaggle \"SETI Breakthrough Listen - E.T. Signal Search\" challenge:\n",
    "- https://www.kaggle.com/competitions/seti-breakthrough-listen\n",
    "\n",
    "This notebook uses a pretrained EfficientNet model to classify the SETI image dataset:\n",
    "- https://rwightman.github.io/pytorch-image-models\n",
    "\n",
    "This is based on the the first place solution for the Kaggle competition:\n",
    "- https://www.kaggle.com/c/seti-breakthrough-listen/discussion/266385\n",
    "- https://www.kaggle.com/code/ligtfeather/eca-nfnet-sam-opt-mixup-k-folds-w-b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05dd96-3644-4987-999e-9f20fe4e4a7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install Python Packages\n",
    "\n",
    "Install packagese required to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15797265-4be7-4f48-8cbd-861d1b7b9696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:33.300576Z",
     "iopub.status.busy": "2022-09-03T19:45:33.300046Z",
     "iopub.status.idle": "2022-09-03T19:45:45.465271Z",
     "shell.execute_reply": "2022-09-03T19:45:45.464579Z",
     "shell.execute_reply.started": "2022-09-03T19:45:33.300555Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: timm in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (0.6.7)\n",
      "Requirement already satisfied: torchvision in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from timm) (0.12.0+cu113)\n",
      "Requirement already satisfied: torch>=1.4 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from timm) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torch>=1.4->timm) (4.3.0)\n",
      "Requirement already satisfied: numpy in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torchvision->timm) (1.23.1)\n",
      "Requirement already satisfied: requests in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torchvision->timm) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (3.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: albumentations in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: PyYAML in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (1.23.1)\n",
      "Requirement already satisfied: scipy in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (1.9.0)\n",
      "Requirement already satisfied: qudida>=0.0.4 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.20.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2022.7.28)\n",
      "Requirement already satisfied: networkx>=2.2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchsummary in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (1.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: AdamP in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (0.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (0.12.21)\n",
      "Requirement already satisfied: psutil>=5.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (5.9.1)\n",
      "Requirement already satisfied: pathtools in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setuptools in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (60.2.0)\n",
      "Requirement already satisfied: setproctitle in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.3.0)\n",
      "Requirement already satisfied: six>=1.13.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.9.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: PyYAML in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (3.20.1)\n",
      "Requirement already satisfied: colorama in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Pretrained models\n",
    "!pip install timm\n",
    "\n",
    "# Image transformations\n",
    "\n",
    "!pip install albumentations\n",
    "\n",
    "# PyTorch configurated to run on GPU (CUDA)\n",
    "# !pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "# Evaluation metrics, such as accuracy\n",
    "!pip install torchsummary\n",
    "\n",
    "# Momentum based gradient descent optimizer\n",
    "!pip install AdamP\n",
    "\n",
    "# API for logging evaluation metrics to the cloud\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec584d4-4573-4863-a81e-49011311b805",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Python Packages\n",
    "\n",
    "Import packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b60974-9c19-42ce-bd33-8f6a6539de7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:45.468242Z",
     "iopub.status.busy": "2022-09-03T19:45:45.467965Z",
     "iopub.status.idle": "2022-09-03T19:45:45.474368Z",
     "shell.execute_reply": "2022-09-03T19:45:45.473533Z",
     "shell.execute_reply.started": "2022-09-03T19:45:45.468210Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Python utility packages\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "# PyTorhc packages for building, running and evaluating models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# Scikit learn utility packages\n",
    "from sklearn.decomposition import NMF # non-negative matrix factorisation\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score # evaluation metrics\n",
    "from sklearn.model_selection import StratifiedKFold # Used for k-Folds cross validation\n",
    "\n",
    "# OpenCV library used for image processing\n",
    "import cv2\n",
    "\n",
    "# Data and processing utility packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Collection of pretrained models\n",
    "import timm\n",
    "\n",
    "# Momentum based gradient descent optimiser\n",
    "from adamp import AdamP\n",
    "\n",
    "# Batch processing helper\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image transformation helpers\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# Utility for logging metrics using a cloud based API\n",
    "import wandb\n",
    "\n",
    "# Graph plotting library\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbd64a-6f44-4163-b303-4872b062e0e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global Configuration\n",
    "\n",
    "Create a configuration object for important values used in the notebook.\n",
    "\n",
    "This makes them easy to track and tweak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fee657-5f4b-497a-8fe3-df9314d21334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:45.475698Z",
     "iopub.status.busy": "2022-09-03T19:45:45.475450Z",
     "iopub.status.idle": "2022-09-03T19:45:45.480515Z",
     "shell.execute_reply": "2022-09-03T19:45:45.479401Z",
     "shell.execute_reply.started": "2022-09-03T19:45:45.475675Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration object for important parameters used in the notebook\n",
    "config = {\n",
    "    'num_workers': 4,\n",
    "    'model': 'efficientnet_b3a',\n",
    "    'device': 'cuda',\n",
    "    'image_size': 224,\n",
    "    'input_channels': 1,\n",
    "    'output_features': 1,\n",
    "    'seed': 42,\n",
    "    'target_size': 1,\n",
    "    'T_max': 10,\n",
    "    'min_lr': 1e-6,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-8,\n",
    "    'batch_size': 100,\n",
    "    'epochs': 1,\n",
    "    'num_folds': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106938e-729e-48b8-9b19-d4e71c2da561",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Seed Initialisation\n",
    "\n",
    "Set random seeds to fixed values so the notebook results are reproducable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2637fb5c-ea85-4019-8829-fdf83bcc6213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:45.482101Z",
     "iopub.status.busy": "2022-09-03T19:45:45.481919Z",
     "iopub.status.idle": "2022-09-03T19:45:45.487397Z",
     "shell.execute_reply": "2022-09-03T19:45:45.485606Z",
     "shell.execute_reply.started": "2022-09-03T19:45:45.482086Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Sets seeds for randomness based functions.\n",
    "'''\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "    \n",
    "# Set the random seeds to a fixed value.    \n",
    "set_seeds(seed=config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ab849-07f8-4129-86e5-cd32aeb0da38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the SETI data samples into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2929a36e-cb44-4108-a30b-fb1553f148e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:45.488310Z",
     "iopub.status.busy": "2022-09-03T19:45:45.488148Z",
     "iopub.status.idle": "2022-09-03T19:45:55.724988Z",
     "shell.execute_reply": "2022-09-03T19:45:55.724391Z",
     "shell.execute_reply.started": "2022-09-03T19:45:45.488296Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build the path to the labels file\n",
    "data_dir = r'D:\\UoL\\Level 6\\CM3070 - Final Project\\SETI Signal Detection\\Data\\train'\n",
    "labels_filepath = os.path.join(data_dir, '500_balanced_labels.npy')\n",
    "\n",
    "# open as a Numpy pickle file\n",
    "with open(labels_filepath, 'rb') as f:\n",
    "    initial_data = np.load(f, allow_pickle=True)\n",
    "\n",
    "# load into a Pandas dataframe\n",
    "initial_data_df = pd.DataFrame(initial_data, columns=['id', 'target', 'image_filepath']).convert_dtypes()\n",
    "initial_data_df['target'] = initial_data_df['target'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687499dc-63f4-460b-b0b6-a82f7af732df",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that the data sample format include three fields:\n",
    "- `id`: Containing the unique ID for the sample\n",
    "- `target`: Indicates if the sample is positive (0) or negative (1)\n",
    "- `image_filepath`: The location of the file containing the sample image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f8ad26-0de7-42c2-8684-c1958d015745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.726162Z",
     "iopub.status.busy": "2022-09-03T19:45:55.725990Z",
     "iopub.status.idle": "2022-09-03T19:45:55.733974Z",
     "shell.execute_reply": "2022-09-03T19:45:55.733452Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.726147Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              1000 non-null   string\n",
      " 1   target          1000 non-null   int32 \n",
      " 2   image_filepath  1000 non-null   string\n",
      "dtypes: int32(1), string(2)\n",
      "memory usage: 19.7 KB\n"
     ]
    }
   ],
   "source": [
    "initial_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30f8d7-098a-4035-a6a4-ce4cad9df526",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split the data with 70% for a training set and 30% for a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7aee7e-c61c-4864-b44c-ead695da5486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.734927Z",
     "iopub.status.busy": "2022-09-03T19:45:55.734735Z",
     "iopub.status.idle": "2022-09-03T19:45:55.738924Z",
     "shell.execute_reply": "2022-09-03T19:45:55.738427Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.734911Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_split_mask = np.random.rand(len(initial_data_df)) < 0.7\n",
    "\n",
    "train_df = initial_data_df[data_split_mask]\n",
    "test_df = initial_data_df[~data_split_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e10f3-524f-4606-a7d4-1d2604adf3c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Image Processing Functions\n",
    "\n",
    "Helper functions for processing the sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8eb161e1",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.739733Z",
     "iopub.status.busy": "2022-09-03T19:45:55.739573Z",
     "iopub.status.idle": "2022-09-03T19:45:55.746191Z",
     "shell.execute_reply": "2022-09-03T19:45:55.745590Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.739719Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Resizes an image to the specified size.\n",
    "'''\n",
    "def resize_image(image):\n",
    "    return cv2.resize(image, dsize=(config['image_size'], config['image_size']), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Plots an image.\n",
    "'''\n",
    "def plot_image(image):\n",
    "    plt.figure(figsize = (20, 6))\n",
    "    plt.imshow(image, aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Min-max normalises the image pixel values (between 0 and 1).\n",
    "'''\n",
    "def normalise_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "\n",
    "    return (image - image_min) / (image_max - image_min)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Factorises an image into two matrices, and returns them.\n",
    "Used to help remove image background noise.\n",
    "'''\n",
    "def get_decomposition_matrices(image):\n",
    "    model = NMF(n_components=2, init='random', random_state=0)\n",
    "    W = model.fit_transform(image + 100) # add 100 to ensure no negative values\n",
    "    H = model.components_\n",
    "\n",
    "    return (W, H)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Removes the background noise from a set of sample images.\n",
    "\n",
    "Based on: https://www.kaggle.com/competitions/seti-breakthrough-listen/discussion/245950\n",
    "'''\n",
    "def get_denoised_image(sample_images):\n",
    "    combined_on_images = None\n",
    "    combined_off_images = None\n",
    "    combined_denoised_image = None\n",
    "\n",
    "    for i in range(0, len(sample_images), 2):\n",
    "        on_target_image = sample_images[i] # Get on target image\n",
    "        off_target_image = sample_images[i+1] # Get off target image\n",
    "\n",
    "        on_W, on_H = get_decomposition_matrices(on_target_image) # Decompose on target images into factor matrices\n",
    "        off_W, off_H = get_decomposition_matrices(off_target_image) # Decomponse off target images into factor matrices\n",
    "        \n",
    "        # Get noise approximation by multiplying a factor matrix from each of the on target, and off target images.\n",
    "        # Then subtract the approximated noise from the on target images\n",
    "        denoised_image = normalise_image(on_target_image - np.matmul(on_W, off_H))\n",
    "\n",
    "        # Consolidate the on target, off target and denoised images.\n",
    "        combined_on_images = on_target_image if combined_on_images is None else combined_on_images + on_target_image\n",
    "        combined_off_images = off_target_image if combined_off_images is None else combined_off_images + off_target_image\n",
    "        combined_denoised_image = denoised_image if combined_denoised_image is None else combined_denoised_image + denoised_image\n",
    "\n",
    "    # Return the denoised image\n",
    "    return combined_denoised_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fd666-528a-4ab7-976e-e32adbaf1050",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Custom Dataset\n",
    "\n",
    "Create a custom dataset class.\n",
    "\n",
    "This is used by the model to interact with a data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e83f521d-c146-492a-afad-4b13fbf2ce8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.746936Z",
     "iopub.status.busy": "2022-09-03T19:45:55.746756Z",
     "iopub.status.idle": "2022-09-03T19:45:55.752046Z",
     "shell.execute_reply": "2022-09-03T19:45:55.751491Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.746921Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, targets, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images_filepath = self.images_filepaths[idx]\n",
    "        images_filepath = images_filepath.replace('\\\\', '/')\n",
    "        file_name = os.path.basename(images_filepath)\n",
    "        images_filepath = '2000/' +  file_name\n",
    "        \n",
    "        images = np.load(BytesIO(dataset[images_filepath]), allow_pickle=True).astype(np.float32)\n",
    "        # images = np.load(images_filepath).astype(np.float32)\n",
    "        image = get_denoised_image(images)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "        else:\n",
    "            image = resize_image(image)\n",
    "            image = image[np.newaxis,:,:]\n",
    "            image = torch.from_numpy(image).float()\n",
    "        \n",
    "        label = torch.tensor(self.targets[idx]).float()\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f62240-81da-4110-b0b6-103ab07cf1e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Image Augmentation\n",
    "\n",
    "Helper functions for transforming images.\n",
    "\n",
    "These can be used to help prevent overfitting on the available data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce9cd0bf-9ce7-4159-b2ad-a757c8fe228a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.754289Z",
     "iopub.status.busy": "2022-09-03T19:45:55.754116Z",
     "iopub.status.idle": "2022-09-03T19:45:55.759162Z",
     "shell.execute_reply": "2022-09-03T19:45:55.758594Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.754274Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns a set of image transformations using the albumentations library.\n",
    "'''\n",
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(config['image_size'], config['image_size']),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=180, p=0.7),\n",
    "            albumentations.RandomBrightnessContrast(brightness_limit=0.6, p=0.5),\n",
    "            albumentations.CoarseDropout(max_holes=10, max_height=12, max_width=12, fill_value=0),\n",
    "            albumentations.ShiftScaleRotate(shift_limit=0.25, scale_limit=0.1, rotate_limit=0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Applies transformations for validation image data.\n",
    "\n",
    "This currently resizes the images.\n",
    "'''\n",
    "def get_valid_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(config['image_size'],config['image_size']),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Applies transformations for training image data.\n",
    "\n",
    "This currently resizes the images.\n",
    "'''\n",
    "def get_test_transforms():\n",
    "        return albumentations.Compose(\n",
    "            [\n",
    "                albumentations.Resize(config['image_size'], config['image_size']),\n",
    "                ToTensorV2(p=1.0)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c665f4-ba86-4749-b576-dabcbbe81928",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mixup\n",
    "\n",
    "Mixup is an image augmentation technique that can also help prevent overfitting on the training data.\n",
    "\n",
    "This works by overlaying two images by applying a transparency effect to the one on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "681f3584-8f00-401b-9910-614f159e5f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.759944Z",
     "iopub.status.busy": "2022-09-03T19:45:55.759784Z",
     "iopub.status.idle": "2022-09-03T19:45:55.764659Z",
     "shell.execute_reply": "2022-09-03T19:45:55.764139Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.759930Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Given two images, x and y, use the alpha value to overlay them.\n",
    "'''\n",
    "def mixup(x, y, alpha=1.0, use_cuda=True):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :] # the composite image\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Criterion to decide how much mixup to apply based on the sample prediction.\n",
    "\n",
    "This allows the model to have a higher representation of samples that\n",
    "it has a higher classification error on.\n",
    "'''\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88ac7c-d4b8-4b8b-b6a6-87b2ddd3611c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metric Monitoring\n",
    "\n",
    "Create utility class and function to track loss, accuracy and AUC ROC metrics.\n",
    "\n",
    "Used with the Weights and Biases web API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b95e56ac-7eb5-43cb-9173-af96513fb393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.765421Z",
     "iopub.status.busy": "2022-09-03T19:45:55.765264Z",
     "iopub.status.idle": "2022-09-03T19:45:55.770642Z",
     "shell.execute_reply": "2022-09-03T19:45:55.770036Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.765407Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Class used by Weights and Biases web API for metric monitoring.\n",
    "'''\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {'val': 0, 'count': 0, 'avg': 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric['val'] += val\n",
    "        metric['count'] += 1\n",
    "        metric['avg'] = metric['val'] / metric['count']\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                '{metric_name}: {avg:.{float_precision}f}'.format(\n",
    "                    metric_name=metric_name, avg=metric['avg'],\n",
    "                    float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "Helper method for returning the ROC AUC score for a prediction.\n",
    "'''\n",
    "def get_roc_auc(output, target):\n",
    "    try:\n",
    "        y_pred = torch.sigmoid(output).cpu()\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "        target = target.cpu()\n",
    "\n",
    "        return roc_auc_score(target, y_pred)\n",
    "    except:\n",
    "        return 0.5 # If an exception occurs, e.g. divide by zero, return a 0.5 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50022801-d8c5-4b8e-8c17-a247403a4154",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Weight Random Sampler\n",
    "\n",
    "Returns a weighted sample from the training dataset.\n",
    "\n",
    "The weighting helps ensure an equal amount of negative and positive samples are returned when there is an unequal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0f0ca22-8222-46a8-b252-3db2932bf2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.771348Z",
     "iopub.status.busy": "2022-09-03T19:45:55.771190Z",
     "iopub.status.idle": "2022-09-03T19:45:55.775770Z",
     "shell.execute_reply": "2022-09-03T19:45:55.775047Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.771334Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Return a sample from the training data.\n",
    "\n",
    "The sample selection is weighted so that there is an equal chance \n",
    "for a sample from each class being selected.\n",
    "'''\n",
    "def get_sampler(train_data):\n",
    "    class_counts = train_data['target'].value_counts().to_list()\n",
    "    num_samples = sum(class_counts)\n",
    "    labels = train_data['target'].to_list()\n",
    "\n",
    "    class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "    weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "\n",
    "    return WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056abd0c-c12a-4a0a-8e73-c7b64aa6432e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train and Validation Dataloaders\n",
    "\n",
    "Data loaders for the training and validation data.\n",
    "\n",
    "These are used during the model training and validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9dd0ba19-0137-4913-bdb2-897ee0a6c52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.776587Z",
     "iopub.status.busy": "2022-09-03T19:45:55.776421Z",
     "iopub.status.idle": "2022-09-03T19:45:55.780574Z",
     "shell.execute_reply": "2022-09-03T19:45:55.779961Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.776573Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_loaders(train_data, valid_data, sampler):\n",
    "    training_set = CustomDataset(\n",
    "        images_filepaths=train_data['image_filepath'].values,\n",
    "        targets=train_data['target'].values,\n",
    "        # transform=get_train_transforms()\n",
    "    )\n",
    "\n",
    "    validation_set = CustomDataset(\n",
    "        images_filepaths=valid_data['image_filepath'].values,\n",
    "        targets=valid_data['target'].values,\n",
    "        # transform=get_valid_transforms()\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        training_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        # shuffle=True,\n",
    "        # num_workers=config['num_workers'],\n",
    "        sampler = sampler,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        validation_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        # num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cdaabb-30cb-4687-8e2a-087c2c5bfc7a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model\n",
    "\n",
    "The deep learning model that will be trained.\n",
    "\n",
    "This is based on a pretrained ECA NFNet model.\n",
    "\n",
    "The final layer is modified so the model outputs a binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5b8b8fd-0b0b-4b87-a6f8-fce978deaa74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.781247Z",
     "iopub.status.busy": "2022-09-03T19:45:55.781093Z",
     "iopub.status.idle": "2022-09-03T19:45:55.785547Z",
     "shell.execute_reply": "2022-09-03T19:45:55.784785Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.781233Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The model that is used for training and classification.\n",
    "\n",
    "Based on a pretrained ECA NFNet model.\n",
    "'''\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, model_name=config['model'], output_features=config['output_features'],\n",
    "                 input_channels=config['input_channels'], pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=input_channels)\n",
    "\n",
    "        # Modify final layer to allow for a binary classification\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, output_features, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ee588-0a2d-45c7-b353-796cb34df1b8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sharpness Aware Minimisation (SAM) Optimiser\n",
    "\n",
    "This techniques helps find regions in the loss landscape that have a uniformly low loss value.\n",
    "\n",
    "This helps avoid sharp dips in the loss value, which aids in model generalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb18d413-022b-445b-bc56-ef8d84adb289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.786375Z",
     "iopub.status.busy": "2022-09-03T19:45:55.786213Z",
     "iopub.status.idle": "2022-09-03T19:45:55.794065Z",
     "shell.execute_reply": "2022-09-03T19:45:55.793494Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.786360Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Class implementing a PyTorch optimiser using the SAM technique.\n",
    "\n",
    "Implementation from: https://github.com/layumi/AdaBoost_Seg/blob/master/sam.py\n",
    "'''\n",
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "                self.state[p][\"e_w\"] = e_w\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None: continue\n",
    "                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        if zero_grad: self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "                    torch.stack([\n",
    "                        p.grad.norm(p=2).to(shared_device)\n",
    "                        for group in self.param_groups for p in group[\"params\"]\n",
    "                        if p.grad is not None\n",
    "                    ]),\n",
    "                    p=2\n",
    "               )\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45228b74-1e35-4363-b7f8-ce49d8945286",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Initialisation\n",
    "\n",
    "Initialise model, loss criterion, optimiser and learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94530cde-2cb0-420d-954f-251bf7115d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:55.794851Z",
     "iopub.status.busy": "2022-09-03T19:45:55.794671Z",
     "iopub.status.idle": "2022-09-03T19:45:56.169398Z",
     "shell.execute_reply": "2022-09-03T19:45:56.168839Z",
     "shell.execute_reply.started": "2022-09-03T19:45:55.794837Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The model to train\n",
    "model = EfficientNet()\n",
    "model = model.to(config['device'])\n",
    "\n",
    "# Loss criterion function for measuring loss\n",
    "criterion = nn.BCEWithLogitsLoss().to(config['device'])\n",
    "\n",
    "# Optimizer used for minimising loss during model training\n",
    "base_optimizer = AdamP\n",
    "optimizer = SAM(model.parameters(), base_optimizer, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "# Learning rate scheduler.\n",
    "# Starts from a high learning rate and steps down to a lower one.\n",
    "scheduler = CosineAnnealingLR(optimizer,\n",
    "                              T_max=config['T_max'],\n",
    "                              eta_min=config['min_lr'],\n",
    "                              last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108ee72-dba7-48ff-8eb2-2d6450ee611d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A summary of the model is shown below.\n",
    "\n",
    "We can see that it contains 184 layers, most of which are 2D convolutional and SiLU activation pairs.\n",
    "\n",
    "There are a total of 21,808,125 model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c026217",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:56.170925Z",
     "iopub.status.busy": "2022-09-03T19:45:56.170463Z",
     "iopub.status.idle": "2022-09-03T19:45:56.219448Z",
     "shell.execute_reply": "2022-09-03T19:45:56.218956Z",
     "shell.execute_reply.started": "2022-09-03T19:45:56.170897Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ScaledStdConv2d-1         [-1, 16, 672, 112]             160\n",
      "              SiLU-2         [-1, 16, 672, 112]               0\n",
      "   ScaledStdConv2d-3         [-1, 32, 672, 112]           4,640\n",
      "              SiLU-4         [-1, 32, 672, 112]               0\n",
      "   ScaledStdConv2d-5         [-1, 64, 672, 112]          18,496\n",
      "              SiLU-6         [-1, 64, 672, 112]               0\n",
      "   ScaledStdConv2d-7         [-1, 128, 336, 56]          73,856\n",
      "              SiLU-8         [-1, 128, 336, 56]               0\n",
      "          Identity-9         [-1, 128, 336, 56]               0\n",
      "  ScaledStdConv2d-10         [-1, 256, 336, 56]          33,024\n",
      "    DownsampleAvg-11         [-1, 256, 336, 56]               0\n",
      "  ScaledStdConv2d-12          [-1, 64, 336, 56]           8,256\n",
      "             SiLU-13          [-1, 64, 336, 56]               0\n",
      "  ScaledStdConv2d-14          [-1, 64, 336, 56]          36,928\n",
      "             SiLU-15          [-1, 64, 336, 56]               0\n",
      "  ScaledStdConv2d-16          [-1, 64, 336, 56]          36,928\n",
      "             SiLU-17          [-1, 64, 336, 56]               0\n",
      "  ScaledStdConv2d-18         [-1, 256, 336, 56]          16,640\n",
      "           Conv1d-19               [-1, 1, 256]               5\n",
      "          Sigmoid-20               [-1, 1, 256]               0\n",
      "        EcaModule-21         [-1, 256, 336, 56]               0\n",
      "         Identity-22         [-1, 256, 336, 56]               0\n",
      "    NormFreeBlock-23         [-1, 256, 336, 56]               0\n",
      "             SiLU-24         [-1, 256, 336, 56]               0\n",
      "        AvgPool2d-25         [-1, 256, 168, 28]               0\n",
      "  ScaledStdConv2d-26         [-1, 512, 168, 28]         131,584\n",
      "    DownsampleAvg-27         [-1, 512, 168, 28]               0\n",
      "  ScaledStdConv2d-28         [-1, 128, 336, 56]          32,896\n",
      "             SiLU-29         [-1, 128, 336, 56]               0\n",
      "  ScaledStdConv2d-30         [-1, 128, 168, 28]          73,856\n",
      "             SiLU-31         [-1, 128, 168, 28]               0\n",
      "  ScaledStdConv2d-32         [-1, 128, 168, 28]          73,856\n",
      "             SiLU-33         [-1, 128, 168, 28]               0\n",
      "  ScaledStdConv2d-34         [-1, 512, 168, 28]          66,048\n",
      "           Conv1d-35               [-1, 1, 512]               5\n",
      "          Sigmoid-36               [-1, 1, 512]               0\n",
      "        EcaModule-37         [-1, 512, 168, 28]               0\n",
      "         Identity-38         [-1, 512, 168, 28]               0\n",
      "    NormFreeBlock-39         [-1, 512, 168, 28]               0\n",
      "             SiLU-40         [-1, 512, 168, 28]               0\n",
      "  ScaledStdConv2d-41         [-1, 128, 168, 28]          65,664\n",
      "             SiLU-42         [-1, 128, 168, 28]               0\n",
      "  ScaledStdConv2d-43         [-1, 128, 168, 28]          73,856\n",
      "             SiLU-44         [-1, 128, 168, 28]               0\n",
      "  ScaledStdConv2d-45         [-1, 128, 168, 28]          73,856\n",
      "             SiLU-46         [-1, 128, 168, 28]               0\n",
      "  ScaledStdConv2d-47         [-1, 512, 168, 28]          66,048\n",
      "           Conv1d-48               [-1, 1, 512]               5\n",
      "          Sigmoid-49               [-1, 1, 512]               0\n",
      "        EcaModule-50         [-1, 512, 168, 28]               0\n",
      "         Identity-51         [-1, 512, 168, 28]               0\n",
      "    NormFreeBlock-52         [-1, 512, 168, 28]               0\n",
      "             SiLU-53         [-1, 512, 168, 28]               0\n",
      "        AvgPool2d-54          [-1, 512, 84, 14]               0\n",
      "  ScaledStdConv2d-55         [-1, 1536, 84, 14]         787,968\n",
      "    DownsampleAvg-56         [-1, 1536, 84, 14]               0\n",
      "  ScaledStdConv2d-57         [-1, 384, 168, 28]         196,992\n",
      "             SiLU-58         [-1, 384, 168, 28]               0\n",
      "  ScaledStdConv2d-59          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-60          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-61          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-62          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-63         [-1, 1536, 84, 14]         591,360\n",
      "           Conv1d-64              [-1, 1, 1536]               5\n",
      "          Sigmoid-65              [-1, 1, 1536]               0\n",
      "        EcaModule-66         [-1, 1536, 84, 14]               0\n",
      "         Identity-67         [-1, 1536, 84, 14]               0\n",
      "    NormFreeBlock-68         [-1, 1536, 84, 14]               0\n",
      "             SiLU-69         [-1, 1536, 84, 14]               0\n",
      "  ScaledStdConv2d-70          [-1, 384, 84, 14]         590,208\n",
      "             SiLU-71          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-72          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-73          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-74          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-75          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-76         [-1, 1536, 84, 14]         591,360\n",
      "           Conv1d-77              [-1, 1, 1536]               5\n",
      "          Sigmoid-78              [-1, 1, 1536]               0\n",
      "        EcaModule-79         [-1, 1536, 84, 14]               0\n",
      "         Identity-80         [-1, 1536, 84, 14]               0\n",
      "    NormFreeBlock-81         [-1, 1536, 84, 14]               0\n",
      "             SiLU-82         [-1, 1536, 84, 14]               0\n",
      "  ScaledStdConv2d-83          [-1, 384, 84, 14]         590,208\n",
      "             SiLU-84          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-85          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-86          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-87          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-88          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-89         [-1, 1536, 84, 14]         591,360\n",
      "           Conv1d-90              [-1, 1, 1536]               5\n",
      "          Sigmoid-91              [-1, 1, 1536]               0\n",
      "        EcaModule-92         [-1, 1536, 84, 14]               0\n",
      "         Identity-93         [-1, 1536, 84, 14]               0\n",
      "    NormFreeBlock-94         [-1, 1536, 84, 14]               0\n",
      "             SiLU-95         [-1, 1536, 84, 14]               0\n",
      "  ScaledStdConv2d-96          [-1, 384, 84, 14]         590,208\n",
      "             SiLU-97          [-1, 384, 84, 14]               0\n",
      "  ScaledStdConv2d-98          [-1, 384, 84, 14]         221,568\n",
      "             SiLU-99          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-100          [-1, 384, 84, 14]         221,568\n",
      "            SiLU-101          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-102         [-1, 1536, 84, 14]         591,360\n",
      "          Conv1d-103              [-1, 1, 1536]               5\n",
      "         Sigmoid-104              [-1, 1, 1536]               0\n",
      "       EcaModule-105         [-1, 1536, 84, 14]               0\n",
      "        Identity-106         [-1, 1536, 84, 14]               0\n",
      "   NormFreeBlock-107         [-1, 1536, 84, 14]               0\n",
      "            SiLU-108         [-1, 1536, 84, 14]               0\n",
      " ScaledStdConv2d-109          [-1, 384, 84, 14]         590,208\n",
      "            SiLU-110          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-111          [-1, 384, 84, 14]         221,568\n",
      "            SiLU-112          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-113          [-1, 384, 84, 14]         221,568\n",
      "            SiLU-114          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-115         [-1, 1536, 84, 14]         591,360\n",
      "          Conv1d-116              [-1, 1, 1536]               5\n",
      "         Sigmoid-117              [-1, 1, 1536]               0\n",
      "       EcaModule-118         [-1, 1536, 84, 14]               0\n",
      "        Identity-119         [-1, 1536, 84, 14]               0\n",
      "   NormFreeBlock-120         [-1, 1536, 84, 14]               0\n",
      "            SiLU-121         [-1, 1536, 84, 14]               0\n",
      " ScaledStdConv2d-122          [-1, 384, 84, 14]         590,208\n",
      "            SiLU-123          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-124          [-1, 384, 84, 14]         221,568\n",
      "            SiLU-125          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-126          [-1, 384, 84, 14]         221,568\n",
      "            SiLU-127          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-128         [-1, 1536, 84, 14]         591,360\n",
      "          Conv1d-129              [-1, 1, 1536]               5\n",
      "         Sigmoid-130              [-1, 1, 1536]               0\n",
      "       EcaModule-131         [-1, 1536, 84, 14]               0\n",
      "        Identity-132         [-1, 1536, 84, 14]               0\n",
      "   NormFreeBlock-133         [-1, 1536, 84, 14]               0\n",
      "            SiLU-134         [-1, 1536, 84, 14]               0\n",
      "       AvgPool2d-135          [-1, 1536, 42, 7]               0\n",
      " ScaledStdConv2d-136          [-1, 1536, 42, 7]       2,360,832\n",
      "   DownsampleAvg-137          [-1, 1536, 42, 7]               0\n",
      " ScaledStdConv2d-138          [-1, 384, 84, 14]         590,208\n",
      "            SiLU-139          [-1, 384, 84, 14]               0\n",
      " ScaledStdConv2d-140           [-1, 384, 42, 7]         221,568\n",
      "            SiLU-141           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-142           [-1, 384, 42, 7]         221,568\n",
      "            SiLU-143           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-144          [-1, 1536, 42, 7]         591,360\n",
      "          Conv1d-145              [-1, 1, 1536]               5\n",
      "         Sigmoid-146              [-1, 1, 1536]               0\n",
      "       EcaModule-147          [-1, 1536, 42, 7]               0\n",
      "        Identity-148          [-1, 1536, 42, 7]               0\n",
      "   NormFreeBlock-149          [-1, 1536, 42, 7]               0\n",
      "            SiLU-150          [-1, 1536, 42, 7]               0\n",
      " ScaledStdConv2d-151           [-1, 384, 42, 7]         590,208\n",
      "            SiLU-152           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-153           [-1, 384, 42, 7]         221,568\n",
      "            SiLU-154           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-155           [-1, 384, 42, 7]         221,568\n",
      "            SiLU-156           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-157          [-1, 1536, 42, 7]         591,360\n",
      "          Conv1d-158              [-1, 1, 1536]               5\n",
      "         Sigmoid-159              [-1, 1, 1536]               0\n",
      "       EcaModule-160          [-1, 1536, 42, 7]               0\n",
      "        Identity-161          [-1, 1536, 42, 7]               0\n",
      "   NormFreeBlock-162          [-1, 1536, 42, 7]               0\n",
      "            SiLU-163          [-1, 1536, 42, 7]               0\n",
      " ScaledStdConv2d-164           [-1, 384, 42, 7]         590,208\n",
      "            SiLU-165           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-166           [-1, 384, 42, 7]         221,568\n",
      "            SiLU-167           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-168           [-1, 384, 42, 7]         221,568\n",
      "            SiLU-169           [-1, 384, 42, 7]               0\n",
      " ScaledStdConv2d-170          [-1, 1536, 42, 7]         591,360\n",
      "          Conv1d-171              [-1, 1, 1536]               5\n",
      "         Sigmoid-172              [-1, 1, 1536]               0\n",
      "       EcaModule-173          [-1, 1536, 42, 7]               0\n",
      "        Identity-174          [-1, 1536, 42, 7]               0\n",
      "   NormFreeBlock-175          [-1, 1536, 42, 7]               0\n",
      " ScaledStdConv2d-176          [-1, 2304, 42, 7]       3,541,248\n",
      "            SiLU-177          [-1, 2304, 42, 7]               0\n",
      "AdaptiveAvgPool2d-178           [-1, 2304, 1, 1]               0\n",
      "         Flatten-179                 [-1, 2304]               0\n",
      "SelectAdaptivePool2d-180                 [-1, 2304]               0\n",
      "          Linear-181                    [-1, 1]           2,305\n",
      "        Identity-182                    [-1, 1]               0\n",
      "  ClassifierHead-183                    [-1, 1]               0\n",
      "     NormFreeNet-184                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 21,808,125\n",
      "Trainable params: 21,808,125\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.15\n",
      "Forward/backward pass size (MB): 1488.66\n",
      "Params size (MB): 83.19\n",
      "Estimated Total Size (MB): 1573.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.cuda(), (1, 1344, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a990419-10dd-40c8-818c-0fb905afa752",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Training Function\n",
    "\n",
    "The training function processes the training data in batches.\n",
    "\n",
    "It makes predictions and then applies back propogation to reduce the loss.\n",
    "\n",
    "The loss, accuracy and ROC AUC metrics are logged using the Weights and Biases wep API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1232dc01-767b-4047-9a46-3d12df5e50c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:56.220569Z",
     "iopub.status.busy": "2022-09-03T19:45:56.220172Z",
     "iopub.status.idle": "2022-09-03T19:45:56.226511Z",
     "shell.execute_reply": "2022-09-03T19:45:56.226002Z",
     "shell.execute_reply.started": "2022-09-03T19:45:56.220552Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Trains the model using training data batches\n",
    "'''\n",
    "def train(train_loader, model, criterion, optimizer, epoch, scheduler):\n",
    "    metric_monitor = MetricMonitor() # Create the W&B metric monitor\n",
    "    model.train() # Put the model in training mode so that weights can be updated\n",
    "    stream = tqdm(enumerate(train_loader), total=len(train_loader)) # Create a stream for processing the data in batches\n",
    "\n",
    "    # iterate over each batch\n",
    "    for i, (images, target) in stream:\n",
    "        images = images.to(config['device'])\n",
    "        target = target.to(config['device']).float().view(-1, 1) # place the images in landscape view\n",
    "        images, targets_a, targets_b, lam = mixup(images, target.view(-1, 1)) # get the images to classify\n",
    "\n",
    "        optimizer.zero_grad() # reset the loss optimizer by zeroing its gradients\n",
    "\n",
    "        output = model(images) # make predictions\n",
    "\n",
    "        # calculate prediction accuracy\n",
    "        accuracy = accuracy_score(target.cpu(), (output.cpu().detach().numpy() > 0), normalize=False)\n",
    "\n",
    "        # calculate prediciton loss\n",
    "        loss = mixup_criterion(criterion, output, targets_a, targets_b, lam)\n",
    "        \n",
    "        # perform back propogation to update model weights\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # step the loss optimizer and reset it\n",
    "        optimizer.first_step(zero_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # update the mixup criterion based on image classification\n",
    "        mixup_criterion(criterion, model(images), targets_a, targets_b, lam).backward()\n",
    "        optimizer.second_step(zero_grad=False)\n",
    "        \n",
    "        # calculate ROC AUC score\n",
    "        roc_auc = get_roc_auc(output, target)\n",
    "\n",
    "        # update metrics in the metric monitor\n",
    "        metric_monitor.update('Loss', loss.item())\n",
    "        metric_monitor.update('Accuracy', accuracy)\n",
    "        metric_monitor.update('ROC AUC', roc_auc)\n",
    "\n",
    "        # log the metric with the W & B web API\n",
    "        wandb.log({ 'Train Epoch': epoch, 'Train Loss': loss.item(), 'Train Accuracy': accuracy, 'Train ROC AUC': roc_auc })\n",
    "\n",
    "        # update stream description so progress can be printed to screen\n",
    "        stream.set_description(\n",
    "            'Epoch: {epoch}. Train. {metric_monitor}'\n",
    "            .format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "        )\n",
    "\n",
    "    # update the learning rate scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448120d-61ba-42ec-bee4-cc6429c2b1e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Validation Function\n",
    "\n",
    "Used to measure the model performanc against the validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "733a89db-333d-4ff5-8ec7-97d7394ab8c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:56.227347Z",
     "iopub.status.busy": "2022-09-03T19:45:56.227192Z",
     "iopub.status.idle": "2022-09-03T19:45:56.232924Z",
     "shell.execute_reply": "2022-09-03T19:45:56.232432Z",
     "shell.execute_reply.started": "2022-09-03T19:45:56.227333Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Validation function measures model performance against the validation data set.\n",
    "\n",
    "Metrics are reported to W & B API.\n",
    "'''\n",
    "def validate(val_loader, model, criterion, epoch):\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval() # place model in validation mode so that weights are not updated\n",
    "    stream = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in stream:\n",
    "            images = images.to(config['device'], non_blocking=True)\n",
    "            target = target.to(config['device'], non_blocking=True).float().view(-1, 1)\n",
    "\n",
    "            output = model(images) # make predictions\n",
    "\n",
    "            # calculate metrics\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = accuracy_score(target.cpu(), (output.cpu().detach().numpy() > 0), normalize=False)\n",
    "            roc_auc = get_roc_auc(output, target)\n",
    "\n",
    "            # update metric monitor with metrics\n",
    "            metric_monitor.update('Loss', loss.item())\n",
    "            metric_monitor.update('Accuracy', accuracy)\n",
    "            metric_monitor.update('ROC AUC', roc_auc)\n",
    "\n",
    "            # report metrics to W & B API\n",
    "            wandb.log(\n",
    "                { 'Validation Epoch': epoch, 'Validation Loss': loss.item(), 'Validation Accuracy': accuracy, 'Validation ROC AUC': roc_auc }\n",
    "            )\n",
    "\n",
    "            stream.set_description(\n",
    "                'Epoch: {epoch}. Validation. {metric_monitor}'\n",
    "                .format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )\n",
    "            \n",
    "            # keep track of predictions and targets to allow further examination\n",
    "            targets = target.detach().cpu().numpy().tolist()\n",
    "            outputs = output.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            final_targets.extend(targets)\n",
    "            final_outputs.extend(outputs)\n",
    "\n",
    "    return final_outputs, final_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda64f1-a9d2-4b6a-8cbd-2f61420d0dcb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a directory to keep the best performing model state, so it can be reused in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51688b9f",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:56.235152Z",
     "iopub.status.busy": "2022-09-03T19:45:56.234984Z",
     "iopub.status.idle": "2022-09-03T19:45:56.241657Z",
     "shell.execute_reply": "2022-09-03T19:45:56.241139Z",
     "shell.execute_reply.started": "2022-09-03T19:45:56.235137Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# name the directory with the current timestamp\n",
    "current_datetime = datetime.now().strftime(\"%y-%m-%d_%H-%M-%S\")\n",
    "models_dir = os.path.join('models', current_datetime)\n",
    "\n",
    "os.mkdir(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef58605b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Validation Loop\n",
    "\n",
    "This loop uses k-folds cross validation to segment the training data and uses the segments in different permutations for training \n",
    "and validation. Allowing the data to be used for more training cycles.\n",
    "\n",
    "It both trains and validates the model for each fold.\n",
    "\n",
    "\n",
    "The best performing model and metrics are stored for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89801c18-46c5-475f-a58e-eddeee0e7ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-03T19:45:56.242717Z",
     "iopub.status.busy": "2022-09-03T19:45:56.242276Z",
     "iopub.status.idle": "2022-09-03T19:47:05.072501Z",
     "shell.execute_reply": "2022-09-03T19:47:05.071863Z",
     "shell.execute_reply.started": "2022-09-03T19:45:56.242702Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:v5ysnr9i) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2895cea087bc4603a692402c6468b620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▇▇▇▇▇█▇▁</td></tr><tr><td>Train Epoch</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▅▆▆▅▆▃█▁</td></tr><tr><td>Train ROC AUC</td><td>▁▁▁▂▂▃▁█</td></tr><tr><td>Validation Accuracy</td><td>▆▆▅▆██▇▁</td></tr><tr><td>Validation Epoch</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Loss</td><td>▇█▇▅▁▂▃▁</td></tr><tr><td>Validation ROC AUC</td><td>▁▁▁█▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>2</td></tr><tr><td>Train Epoch</td><td>1</td></tr><tr><td>Train Loss</td><td>0.64762</td></tr><tr><td>Train ROC AUC</td><td>1.0</td></tr><tr><td>Validation Accuracy</td><td>2</td></tr><tr><td>Validation Epoch</td><td>1</td></tr><tr><td>Validation Loss</td><td>0.65919</td></tr><tr><td>Validation ROC AUC</td><td>0.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">22-09-03_19-42-03 - fold 0</strong>: <a href=\"https://wandb.ai/mllm3/SETI/runs/v5ysnr9i\" target=\"_blank\">https://wandb.ai/mllm3/SETI/runs/v5ysnr9i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220903_194203-v5ysnr9i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:v5ysnr9i). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220903_194556-3chsm9zm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mllm3/SETI/runs/3chsm9zm\" target=\"_blank\">22-09-03_19-45-56 - fold 0</a></strong> to <a href=\"https://wandb.ai/mllm3/SETI\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Fold: 0 ========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train. Loss: 0.690 | Accuracy: 44.750 | ROC AUC: 0.599: 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]\n",
      "/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epoch: 1. Validation. Loss: 0.688 | Accuracy: 46.000 | ROC AUC: 0.504: 100%|██████████| 8/8 [00:09<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC in fold 0 was 0.5380\n",
      "Final ROC-AUC in fold 0 was 0.5380\n",
      "Best model name in fold 0 was eca_nfnet_l0_fold_0_epoch_1_roc_auc_0.538.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3chsm9zm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dc6db3bcd84f8781d9d870ed20a980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▇▇▇▇▇█▇▁</td></tr><tr><td>Train Epoch</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▅▆▆▅▆▃█▁</td></tr><tr><td>Train ROC AUC</td><td>▁▁▁▂▂▃▁█</td></tr><tr><td>Validation Accuracy</td><td>▆▆▅▆██▇▁</td></tr><tr><td>Validation Epoch</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation Loss</td><td>▇█▇▅▁▂▃▁</td></tr><tr><td>Validation ROC AUC</td><td>▁▁▁█▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>2</td></tr><tr><td>Train Epoch</td><td>1</td></tr><tr><td>Train Loss</td><td>0.64762</td></tr><tr><td>Train ROC AUC</td><td>1.0</td></tr><tr><td>Validation Accuracy</td><td>2</td></tr><tr><td>Validation Epoch</td><td>1</td></tr><tr><td>Validation Loss</td><td>0.65919</td></tr><tr><td>Validation ROC AUC</td><td>0.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">22-09-03_19-45-56 - fold 0</strong>: <a href=\"https://wandb.ai/mllm3/SETI/runs/3chsm9zm\" target=\"_blank\">https://wandb.ai/mllm3/SETI/runs/3chsm9zm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220903_194556-3chsm9zm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3chsm9zm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220903_194629-sqf8fxx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mllm3/SETI/runs/sqf8fxx7\" target=\"_blank\">22-09-03_19-45-56 - fold 1</a></strong> to <a href=\"https://wandb.ai/mllm3/SETI\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Fold: 1 ========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train. Loss: 0.691 | Accuracy: 43.125 | ROC AUC: 0.563: 100%|██████████| 8/8 [00:12<00:00,  1.58s/it]\n",
      "Epoch: 1. Validation. Loss: 0.678 | Accuracy: 46.625 | ROC AUC: 0.517: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC in fold 1 was 0.5900\n",
      "Final ROC-AUC in fold 1 was 0.5900\n",
      "Best model name in fold 1 was eca_nfnet_l0_fold_1_epoch_1_roc_auc_0.59.pth\n"
     ]
    }
   ],
   "source": [
    "# keep track of best metrics and best model state\n",
    "best_roc_auc = -np.inf\n",
    "best_epoch = -np.inf\n",
    "best_model_name = None\n",
    "best_model_state = None\n",
    "\n",
    "# create the folds for k-folds cross validation\n",
    "k_fold = StratifiedKFold(n_splits=config['num_folds'], shuffle=True, random_state=config['seed'])\n",
    "\n",
    "\n",
    "\n",
    "# iterate through each fold\n",
    "for fold, (trn_idx, val_idx) in enumerate(k_fold.split(train_df, train_df['target'])):\n",
    "    # initialise W&B for storing the metrics in\n",
    "    run = wandb.init(\n",
    "            project='SETI',\n",
    "            config=config,\n",
    "            job_type='train',\n",
    "            name=f\"{current_datetime} - fold {fold}\")\n",
    "\n",
    "    # print the current fold\n",
    "    print(f\"{'='*40} Fold: {fold} {'='*40}\")\n",
    "\n",
    "    # get the training and validation samples\n",
    "    train_data = train_df.iloc[trn_idx]\n",
    "    valid_data = train_df.iloc[val_idx]\n",
    "\n",
    "    # initialise the data sampler on the training data\n",
    "    sampler = get_sampler(train_data)\n",
    "\n",
    "    # get the training and validation data loaders\n",
    "    train_loader, valid_loader = get_loaders(train_data, valid_data, sampler)\n",
    "\n",
    "    # iterater through each training epoch\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        # perform the model training and validation\n",
    "        train(train_loader, model, criterion, optimizer, epoch, scheduler)\n",
    "        valid_predictions, valid_targets = validate(valid_loader, model, criterion, epoch)\n",
    "\n",
    "        # calculate the validation ROC AUC\n",
    "        valid_roc_auc = round(roc_auc_score(valid_targets, valid_predictions), 3)\n",
    "\n",
    "        # keep the metrics and model state for the predictions with the best validation ROC AUC \n",
    "        if valid_roc_auc > best_roc_auc:\n",
    "            best_roc_auc = valid_roc_auc\n",
    "            best_epoch = epoch\n",
    "            best_model_name = f\"{config['model']}_fold_{fold}_epoch_{epoch}_roc_auc_{valid_roc_auc}.pth\"\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # save the best performing model state\n",
    "    torch.save(best_model_state, os.path.join(models_dir, best_model_name))\n",
    "\n",
    "    # print the best ROC AUC scores and model state for the fold\n",
    "    print(f'Best ROC-AUC in fold {fold} was {best_roc_auc:.4f}')\n",
    "    print(f'Final ROC-AUC in fold {fold} was {valid_roc_auc:.4f}')\n",
    "    print(f'Best model name in fold {fold} was {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11edcb5e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Now the best performing model will run against the test data.\n",
    "\n",
    "This gives a good indication of real life model performance, because the model has not seen the test data at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5eb43510",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:47:05.073688Z",
     "iopub.status.busy": "2022-09-03T19:47:05.073497Z",
     "iopub.status.idle": "2022-09-03T19:47:05.077572Z",
     "shell.execute_reply": "2022-09-03T19:47:05.076989Z",
     "shell.execute_reply.started": "2022-09-03T19:47:05.073668Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data loader for the test data.\n",
    "'''\n",
    "\n",
    "def get_test_loader(test_data):\n",
    "    test_set = CustomDataset(\n",
    "        images_filepaths=test_data['image_filepath'].values,\n",
    "        targets=test_data['target'].values\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        test_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        # num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516573e8-3f3c-4b7b-a14e-d9d5f7306277",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the model agains the test data and log the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ebd57b3",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:47:05.078411Z",
     "iopub.status.busy": "2022-09-03T19:47:05.078258Z",
     "iopub.status.idle": "2022-09-03T19:47:05.084534Z",
     "shell.execute_reply": "2022-09-03T19:47:05.083872Z",
     "shell.execute_reply.started": "2022-09-03T19:47:05.078398Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function for testing a model against the test dataset.\n",
    "\n",
    "It returns the model predictions for the ground truth labels.\n",
    "'''\n",
    "def test_model(model_state):\n",
    "    # keep track of the predictions and ground truth labels\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    # initialise the model and place it in evaluation mode\n",
    "    model = EfficientNet()\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    # initialise the metric monitor for reporting progress\n",
    "    metric_monitor = MetricMonitor()\n",
    "    \n",
    "    # initialise the test data loader with the test data\n",
    "    test_loader = get_test_loader(test_df)\n",
    "    \n",
    "    # create the stream for iterating through the test data batch\n",
    "    stream = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    with torch.no_grad(): # don't perform any back propogation as we only want to evaluate\n",
    "        for i, (images, target) in stream: # iterate through each test data batch\n",
    "            images = images.to('cpu', non_blocking=True)\n",
    "            target = target.to('cpu', non_blocking=True).float().view(-1, 1)\n",
    "\n",
    "            # make predictions\n",
    "            output = model(images)\n",
    "\n",
    "            # calculate metric performance metrics\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = accuracy_score(target.cpu(), (output.cpu().detach().numpy() > 0), normalize=False)\n",
    "            roc_auc = get_roc_auc(output, target)\n",
    "\n",
    "            # report the metrics to the monitor for displaying model progress\n",
    "            metric_monitor.update('Loss', loss.item())\n",
    "            metric_monitor.update('ROC AUC', roc_auc)\n",
    "\n",
    "            # report the metrics the W&B web API\n",
    "            wandb.log({'Test Loss': loss.item(), 'Test Accuracy': accuracy, 'Test ROC AUC': roc_auc})\n",
    "\n",
    "            # print the current model progress\n",
    "            stream.set_description('Test {metric_monitor}'.format(metric_monitor=metric_monitor))\n",
    "\n",
    "            # get the ground truth labels and predictions so they can be returned\n",
    "            targets = target.detach().cpu().numpy().tolist()\n",
    "            outputs = output.detach().cpu().numpy().tolist()\n",
    "\n",
    "            final_targets.extend(targets)\n",
    "            final_outputs.extend(outputs)\n",
    "\n",
    "    # return predictions and ground truth labels\n",
    "    return final_outputs, final_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a414c-88d6-421b-9bc4-69e5a8abc6ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the model against the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7bc2aced",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:47:05.085455Z",
     "iopub.status.busy": "2022-09-03T19:47:05.085284Z",
     "iopub.status.idle": "2022-09-03T19:47:32.432720Z",
     "shell.execute_reply": "2022-09-03T19:47:32.432105Z",
     "shell.execute_reply.started": "2022-09-03T19:47:05.085440Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.691 | ROC AUC: 0.489: 100%|██████████| 6/6 [00:27<00:00,  4.51s/it]\n"
     ]
    }
   ],
   "source": [
    "test_outputs, test_targets = test_model(best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be979a-bf3b-470d-ac48-e4d797317963",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a dataframe with the predictions and ground truch labels to help make the result evaluation easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a44d0365",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:47:32.433846Z",
     "iopub.status.busy": "2022-09-03T19:47:32.433663Z",
     "iopub.status.idle": "2022-09-03T19:47:32.448824Z",
     "shell.execute_reply": "2022-09-03T19:47:32.447986Z",
     "shell.execute_reply.started": "2022-09-03T19:47:32.433831Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame([test_targets, test_outputs])\n",
    "test_results_df = test_results_df.transpose()\n",
    "test_results_df.columns = ['label', 'prediction']\n",
    "\n",
    "test_results_df['label'] = test_results_df['label'].apply(lambda x: x[0])\n",
    "test_results_df['prediction'] = test_results_df['prediction'].apply(lambda x: x[0])\n",
    "\n",
    "# Use threshold of > 0.5 for a positive prediction, else it is a negative prediction\n",
    "test_results_df['prediction'] = test_results_df['prediction'].apply(lambda x: 1.0 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d59e3-df6b-46aa-b78f-a8f8a7ed3656",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Display a confusion matrix for an overview of how well the model predicted each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82b90718",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:47:32.450336Z",
     "iopub.status.busy": "2022-09-03T19:47:32.449946Z",
     "iopub.status.idle": "2022-09-03T19:47:32.463979Z",
     "shell.execute_reply": "2022-09-03T19:47:32.463579Z",
     "shell.execute_reply.started": "2022-09-03T19:47:32.450292Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>268</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label       0.0  1.0\n",
       "prediction          \n",
       "0.0         268  273\n",
       "1.0          20   34"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test_results_df['prediction'], test_results_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8e458-3b23-4204-ad31-5b5aa053f010",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Display the standard metrics for the test results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dae8a35d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-09-03T19:47:32.467515Z",
     "iopub.status.busy": "2022-09-03T19:47:32.467176Z",
     "iopub.status.idle": "2022-09-03T19:47:32.473966Z",
     "shell.execute_reply": "2022-09-03T19:47:32.473552Z",
     "shell.execute_reply.started": "2022-09-03T19:47:32.467499Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.50      0.65       541\n",
      "         1.0       0.11      0.63      0.19        54\n",
      "\n",
      "    accuracy                           0.51       595\n",
      "   macro avg       0.52      0.56      0.42       595\n",
      "weighted avg       0.86      0.51      0.60       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_results_df['prediction'], test_results_df['label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}