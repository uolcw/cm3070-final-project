{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SETI Breakthrough Listen challenge solution using a model ensemble\n",
    "\n",
    "This notebook presents a solution to the Kaggle “SETI Breakthrough Listen - E.T. Signal Search” challenge:\n",
    "- https://www.kaggle.com/competitions/seti-breakthrough-listen\n",
    "\n",
    "The ensemble approach is based on the following backbone models that have been trained on the SETI dataset:\n",
    "- ECA NFNet\n",
    "- EfficientNet\n",
    "- Regnet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Install Python Packages\n",
    "\n",
    "Install packagese required to run this notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: timm in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (0.6.7)\n",
      "Requirement already satisfied: torch>=1.4 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from timm) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from timm) (0.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torch>=1.4->timm) (4.3.0)\n",
      "Requirement already satisfied: numpy in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torchvision->timm) (1.23.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: requests in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from torchvision->timm) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests->torchvision->timm) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: albumentations in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: qudida>=0.0.4 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (1.23.1)\n",
      "Requirement already satisfied: PyYAML in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: scipy in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from albumentations) (1.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2022.7.28)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchsummary in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (1.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: AdamP in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (0.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: wandb in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (0.12.21)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (3.20.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.9.0)\n",
      "Requirement already satisfied: six>=1.13.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (5.9.1)\n",
      "Requirement already satisfied: PyYAML in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.0.9)\n",
      "Requirement already satisfied: setuptools in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (60.2.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: setproctitle in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from wandb) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\uol\\level 6\\cm3070 - final project\\seti signal detection\\prototype\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Pretrained models\n",
    "!pip install timm\n",
    "\n",
    "# Image transformations\n",
    "\n",
    "!pip install albumentations\n",
    "\n",
    "# PyTorch configured to run on GPU (CUDA)\n",
    "# !pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "# Evaluation metrics, such as accuracy\n",
    "!pip install torchsummary\n",
    "\n",
    "# Momentum based gradient descent optimizer\n",
    "!pip install AdamP\n",
    "\n",
    "# API for logging evaluation metrics to the cloud\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Python Packages\n",
    "\n",
    "Import packages used in this notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Python utility packages\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "# PyTorhc packages for building, running and evaluating models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# Scikit learn utility packages\n",
    "from sklearn.decomposition import NMF # non-negative matrix factorisation\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score # evaluation metrics\n",
    "from sklearn.model_selection import StratifiedKFold # Used for k-Folds cross validation\n",
    "\n",
    "# OpenCV library used for image processing\n",
    "import cv2\n",
    "\n",
    "# Data and processing utility packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Collection of pretrained models\n",
    "import timm\n",
    "\n",
    "# Momentum based gradient descent optimiser\n",
    "from adamp import AdamP\n",
    "\n",
    "# Batch processing helper\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image transformation helpers\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# Utility for logging metrics using a cloud based API\n",
    "import wandb\n",
    "\n",
    "# Graph plotting library\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global Configuration\n",
    "\n",
    "Create a configuration object for important values used in the notebook.\n",
    "\n",
    "This makes them easy to track and tweak."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Configuration object for important parameters used in the notebook\n",
    "config = {\n",
    "    'num_workers': 4,\n",
    "    'model': 'nf_regnet_b5',\n",
    "    'device': 'cuda',\n",
    "    'image_size': 224,\n",
    "    'input_channels': 1,\n",
    "    'output_features': 1,\n",
    "    'seed': 42,\n",
    "    'target_size': 1,\n",
    "    'T_max': 10,\n",
    "    'min_lr': 1e-6,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-8,\n",
    "    'batch_size': 100,\n",
    "    'epochs': 1,\n",
    "    'num_folds': 2,\n",
    "    'wandb_project': 'SETI - 300 epochs - transform - 2',\n",
    "    'wandb_run_name': 'ensemble'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Seed Initialisation\n",
    "\n",
    "Set random seeds to fixed values so the notebook results are reproducable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "'''\n",
    "Sets seeds for randomness based functions.\n",
    "'''\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "# Set the random seeds to a fixed value.\n",
    "set_seeds(seed=config['seed'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the SETI dataset labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3480657674.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [6]\u001B[1;36m\u001B[0m\n\u001B[1;33m    Load the SETI dataset labels.\u001B[0m\n\u001B[1;37m         ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_dir = r'D:\\UoL\\Level 6\\CM3070 - Final Project\\SETI Signal Detection\\Data\\2000 dataset'\n",
    "labels_filepath = os.path.join(data_dir, '2000_balanced_labels.npy')\n",
    "\n",
    "with open(labels_filepath, 'rb') as f:\n",
    "    initial_data = np.load(f, allow_pickle=True)\n",
    "\n",
    "initial_data_df = pd.DataFrame(initial_data, columns=['id', 'target', 'image_filepath']).convert_dtypes()\n",
    "initial_data_df['target'] = initial_data_df['target'].astype('int')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              2000 non-null   string\n",
      " 1   target          2000 non-null   int32 \n",
      " 2   image_filepath  2000 non-null   string\n",
      "dtypes: int32(1), string(2)\n",
      "memory usage: 39.2 KB\n"
     ]
    }
   ],
   "source": [
    "initial_data_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the data sample format include three fields:\n",
    "- `id`: Containing the unique ID for the sample\n",
    "- `target`: Indicates if the sample is positive (0) or negative (1)\n",
    "- `image_filepath`: The location of the file containing the sample image data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data with 70% for a training set and 30% for a test set:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_split_mask = np.random.rand(len(initial_data_df)) < 0.7\n",
    "\n",
    "train_df = initial_data_df[data_split_mask]\n",
    "test_df = initial_data_df[~data_split_mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Processing Functions\n",
    "\n",
    "Helper functions for processing the sample images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "'''\n",
    "Resizes an image to the specified size.\n",
    "'''\n",
    "def resize_image(image):\n",
    "    return cv2.resize(image, dsize=(config['image_size'], config['image_size']), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Plots an image.\n",
    "'''\n",
    "def plot_image(image):\n",
    "    plt.figure(figsize = (20, 6))\n",
    "    plt.imshow(image, aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Min-max normalises the image pixel values (between 0 and 1).\n",
    "'''\n",
    "def normalise_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "\n",
    "    return (image - image_min) / (image_max - image_min)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Factorises an image into two matrices, and returns them.\n",
    "Used to help remove image background noise.\n",
    "'''\n",
    "def get_decomposition_matrices(image):\n",
    "    model = NMF(n_components=2, init='random', random_state=0)\n",
    "    W = model.fit_transform(image + 100) # add 100 to ensure no negative values\n",
    "    H = model.components_\n",
    "\n",
    "    return (W, H)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Removes the background noise from a set of sample images.\n",
    "\n",
    "Based on: https://www.kaggle.com/competitions/seti-breakthrough-listen/discussion/245950\n",
    "'''\n",
    "def get_denoised_image(sample_images):\n",
    "    combined_on_images = None\n",
    "    combined_off_images = None\n",
    "    combined_denoised_image = None\n",
    "\n",
    "    for i in range(0, len(sample_images), 2):\n",
    "        on_target_image = sample_images[i] # Get on target image\n",
    "        off_target_image = sample_images[i+1] # Get off target image\n",
    "\n",
    "        on_W, on_H = get_decomposition_matrices(on_target_image) # Decompose on target images into factor matrices\n",
    "        off_W, off_H = get_decomposition_matrices(off_target_image) # Decomponse off target images into factor matrices\n",
    "\n",
    "        # Get noise approximation by multiplying a factor matrix from each of the on target, and off target images.\n",
    "        # Then subtract the approximated noise from the on target images\n",
    "        denoised_image = normalise_image(on_target_image - np.matmul(on_W, off_H))\n",
    "\n",
    "        # Consolidate the on target, off target and denoised images.\n",
    "        combined_on_images = on_target_image if combined_on_images is None else combined_on_images + on_target_image\n",
    "        combined_off_images = off_target_image if combined_off_images is None else combined_off_images + off_target_image\n",
    "        combined_denoised_image = denoised_image if combined_denoised_image is None else combined_denoised_image + denoised_image\n",
    "\n",
    "    # Return the denoised image\n",
    "    return combined_denoised_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Dataset\n",
    "\n",
    "Create a custom dataset class.\n",
    "\n",
    "This is used by the model to interact with a data sample."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, targets, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images_filepath = self.images_filepaths[idx]\n",
    "        images = np.load(images_filepath).astype(np.float32)\n",
    "        image = get_denoised_image(images)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)['image']\n",
    "        else:\n",
    "            image = resize_image(image)\n",
    "            image = image[np.newaxis,:,:]\n",
    "            image = torch.from_numpy(image).float()\n",
    "\n",
    "        label = torch.tensor(self.targets[idx]).float()\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metric Monitoring\n",
    "\n",
    "Create utility class and function to track loss, accuracy and AUC ROC metrics.\n",
    "\n",
    "Used with the Weights and Biases web API."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "'''\n",
    "Class used by Weights and Biases web API for metric monitoring.\n",
    "'''\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {'val': 0, 'count': 0, 'avg': 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric['val'] += val\n",
    "        metric['count'] += 1\n",
    "        metric['avg'] = metric['val'] / metric['count']\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                '{metric_name}: {avg:.{float_precision}f}'.format(\n",
    "                    metric_name=metric_name, avg=metric['avg'],\n",
    "                    float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Helper method for returning the ROC AUC score for a prediction.\n",
    "'''\n",
    "def get_roc_auc(output, target):\n",
    "    try:\n",
    "        y_pred = torch.sigmoid(output).cpu()\n",
    "        y_pred = y_pred.detach().numpy()\n",
    "        target = target.cpu()\n",
    "\n",
    "        return roc_auc_score(target, y_pred)\n",
    "    except:\n",
    "        return 0.5 # If an exception occurs, e.g. divide by zero, return a 0.5 score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Classes\n",
    "\n",
    "Create the classes for the models that will be used for classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "'''\n",
    "ECA NFNet model.\n",
    "'''\n",
    "class EcaNFNet(nn.Module):\n",
    "    def __init__(self, model_name='eca_nfnet_l0', output_features=config['output_features'],\n",
    "                 input_channels=config['input_channels'], pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=input_channels)\n",
    "\n",
    "        # Modify final layer to allow for a binary classification\n",
    "        n_features = self.model.head.fc.in_features\n",
    "        self.model.head.fc = nn.Linear(n_features, output_features, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "'''\n",
    "RegNet model.\n",
    "'''\n",
    "class RegNet(nn.Module):\n",
    "    def __init__(self, model_name='nf_regnet_b1', output_features=config['output_features'],\n",
    "                 input_channels=config['input_channels'], pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=input_channels)\n",
    "\n",
    "        # Modify final layer to allow for a binary classification\n",
    "        n_features = self.model.head.fc.in_features\n",
    "        self.model.head.fc = nn.Linear(n_features, output_features, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "'''\n",
    "EfficientNet model.\n",
    "'''\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, model_name='tf_efficientnet_b3', output_features=config['output_features'],\n",
    "                 input_channels=config['input_channels'], pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=input_channels)\n",
    "\n",
    "        # Modify final layer to allow for a binary classification\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, output_features, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss Criterion\n",
    "\n",
    "Define a loss criterion function for measuring loss:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(config['device'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loader\n",
    "\n",
    "Data loader used during classification to access the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "'''\n",
    "Data loader for the test data.\n",
    "'''\n",
    "\n",
    "def get_test_loader(test_data):\n",
    "    test_set = CustomDataset(\n",
    "        images_filepaths=test_data['image_filepath'].values,\n",
    "        targets=test_data['target'].values\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        test_set,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        # num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Function\n",
    "\n",
    "The function used to classify a model against the test dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "'''\n",
    "Function for testing a model against the test dataset.\n",
    "\n",
    "It receives a model and model state to restore as input.\n",
    "It returns the model predictions for the ground truth labels.\n",
    "'''\n",
    "def test_model(model, model_state_file):\n",
    "    # keep track of the predictions and ground truth labels\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    # initialise the model and place it in evaluation mode\n",
    "    model_state = torch.load(os.path.join('ensemble models', model_state_file))\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    # initialise the metric monitor for reporting progress\n",
    "    metric_monitor = MetricMonitor()\n",
    "\n",
    "    # initialise the test data loader with the test data\n",
    "    test_loader = get_test_loader(test_df)\n",
    "\n",
    "    # create the stream for iterating through the test data batch\n",
    "    stream = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    with torch.no_grad(): # don't perform any back propogation as we only want to evaluate\n",
    "        for i, (images, target) in stream: # iterate through each test data batch\n",
    "            images = images.to('cpu', non_blocking=True)\n",
    "            target = target.to('cpu', non_blocking=True).float().view(-1, 1)\n",
    "\n",
    "            # make predictions\n",
    "            output = model(images)\n",
    "\n",
    "            # calculate metric performance metrics\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = accuracy_score(target.cpu(), (output.cpu().detach().numpy() > 0), normalize=False)\n",
    "            roc_auc = get_roc_auc(output, target)\n",
    "\n",
    "            # report the metrics to the monitor for displaying model progress\n",
    "            metric_monitor.update('Loss', loss.item())\n",
    "            metric_monitor.update('ROC AUC', roc_auc)\n",
    "\n",
    "            # report the metrics the W&B web API\n",
    "            wandb.log({'Test Loss': loss.item(), 'Test Accuracy': accuracy, 'Test ROC AUC': roc_auc})\n",
    "\n",
    "            # print the current model progress\n",
    "            stream.set_description('Test {metric_monitor}'.format(metric_monitor=metric_monitor))\n",
    "\n",
    "            # get the ground truth labels and predictions, so they can be returned\n",
    "            targets = target.detach().cpu().numpy().tolist()\n",
    "            outputs = output.detach().cpu().numpy().tolist()\n",
    "\n",
    "            final_targets.extend(targets)\n",
    "            final_outputs.extend(outputs)\n",
    "\n",
    "    # return predictions and ground truth labels\n",
    "    return final_outputs, final_targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weights and Biases Initialisation\n",
    "\n",
    "Initialise W&B with the project and run name to log metrics to."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmllm3\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.13.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.21"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>D:\\UoL\\Level 6\\CM3070 - Final Project\\SETI Signal Detection\\Prototype\\wandb\\run-20220904_153713-3g8l2i8k</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/mllm3/SETI%20-%20300%20epochs%20-%20transform%20-%202/runs/3g8l2i8k\" target=\"_blank\">ensemble</a></strong> to <a href=\"https://wandb.ai/mllm3/SETI%20-%20300%20epochs%20-%20transform%20-%202\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mllm3/SETI%20-%20300%20epochs%20-%20transform%20-%202/runs/3g8l2i8k?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x24a448b2fd0>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=config['wandb_project'],\n",
    "    config=config,\n",
    "    job_type='test',\n",
    "    name=config['wandb_run_name']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Predictions\n",
    "\n",
    "Instantiate models with states saved from when they were previously trained on the SETI dataset.\n",
    "\n",
    "Then get their predictions against the test set:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.945 | ROC AUC: 0.506: 100%|██████████| 6/6 [03:00<00:00, 30.10s/it]\n",
      "Test Loss: 1.066 | ROC AUC: 0.492: 100%|██████████| 6/6 [01:14<00:00, 12.43s/it]\n",
      "Test Loss: 0.831 | ROC AUC: 0.508: 100%|██████████| 6/6 [02:20<00:00, 23.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialise models to test\n",
    "ecanfnet_model = EcaNFNet()\n",
    "regnet_model = RegNet()\n",
    "efficientnet_model = EfficientNet()\n",
    "\n",
    "\n",
    "# get model predictions against test data\n",
    "ecanfnet_outputs, ecanfnet_targets = test_model(ecanfnet_model, 'eca_nfnet_l0_fold_2_epoch_1_roc_auc_0.999.pth')\n",
    "regnet_outputs, regnet_targets = test_model(regnet_model, 'nf_regnet_b1_fold_2_epoch_1_roc_auc_0.998.pth')\n",
    "efficientnet_outputs, efficientnet_targets = test_model(efficientnet_model, 'tf_efficientnet_b3_fold_2_epoch_2_roc_auc_0.999.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "'''\n",
    "Returns a dataframe composed of ground truth labels and binary classifications.\n",
    "'''\n",
    "def get_predictions_dataframe(targets, predictions):\n",
    "    results_df = pd.DataFrame([targets, predictions])\n",
    "    results_df = results_df.transpose()\n",
    "    results_df.columns = ['label', 'prediction']\n",
    "\n",
    "    results_df['label'] = results_df['label'].apply(lambda x: x[0])\n",
    "    results_df['prediction'] = results_df['prediction'].apply(lambda x: x[0])\n",
    "\n",
    "    # Use threshold of > 0.5 for a positive prediction, else it is a negative prediction\n",
    "    results_df['prediction'] = results_df['prediction'].apply(lambda x: 1.0 if x > 0.5 else 0)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "# get predictions for each model\n",
    "ecanfnet_results_df = get_predictions_dataframe(ecanfnet_targets, ecanfnet_outputs)\n",
    "regnet_results_df = get_predictions_dataframe(regnet_targets, regnet_outputs)\n",
    "efficientnet_results_df = get_predictions_dataframe(efficientnet_targets, efficientnet_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble Predictions\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   label  prediction\n0    0.0         1.0\n1    0.0         1.0\n2    0.0         0.0\n3    0.0         0.0\n4    0.0         0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_results_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "'''\n",
    "Given three predictions, returns their mode value.\n",
    "'''\n",
    "def get_mode_prediction(prediction_1, prediction_2, prediction_3):\n",
    "    predictions = pd.Series([prediction_1, prediction_2, prediction_3])\n",
    "\n",
    "    return predictions.mode()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# build dataframe with all of the results\n",
    "ensemble_results_df = pd.DataFrame()\n",
    "\n",
    "ensemble_results_df['label'] = efficientnet_results_df['label']\n",
    "\n",
    "ensemble_results_df['ecanfnet_prediction'] = efficientnet_results_df['prediction']\n",
    "ensemble_results_df['regnet_prediction'] = regnet_results_df['prediction']\n",
    "ensemble_results_df['efficientnet_prediction'] = efficientnet_results_df['prediction']\n",
    "\n",
    "# get the mode prediction for each row for the ensemble prediction\n",
    "ensemble_results_df['ensemble_prediction'] = ensemble_results_df.apply(\n",
    "    lambda row: get_mode_prediction(row['ecanfnet_prediction'], row['regnet_prediction'], row['efficientnet_prediction']),\n",
    "    axis=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print metrics for the ensemble predictions:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "label       0.0  1.0\nprediction          \n0.0         189  176\n1.0          99  131",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>label</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>prediction</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>189</td>\n      <td>176</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>99</td>\n      <td>131</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(ensemble_results_df['ensemble_prediction'], ensemble_results_df['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.52      0.58       366\n",
      "         1.0       0.43      0.58      0.49       229\n",
      "\n",
      "    accuracy                           0.54       595\n",
      "   macro avg       0.55      0.55      0.54       595\n",
      "weighted avg       0.57      0.54      0.55       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ensemble_results_df['ensemble_prediction'], ensemble_results_df['label']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}